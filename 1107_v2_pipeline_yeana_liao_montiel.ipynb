{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NAkKL_FFFr4w"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From now on, please replace your ChatGPT usage with your GPT API key (GPT-5 model). In this way, you don’t have to copy and paste things back-and-forth to prompt GPT. Instead, you can import input from a CSV or export output to a CSV file.\n",
        "\n",
        "https://dl.acm.org/doi/pdf/10.1145/3715772\n",
        "\n",
        "Please also ensure the temperature setting of the GPT model you use to be 0, to minimize randomness.For each jetbrain rule, please provide the syntax/examples/built-in functions. Ask GPT to output (1) the corresponding RSL rule based on the chosen library/framework, (2) explanation of the newly introduced functions if there is a new function, (3) URL of the third-party data source supporting that rule, (4) summary of the description from the third-party web page supporting that rule, and (5) its (model's) validation of the generated rule based on the jetbrain rule as well as the located third-party data source.\n",
        "The prompt mimics Chain-of-Thought as it asks GPT to provide supporting facts, and validate the generated rule based on the given fact as well as retrieved support fact.\n",
        "\n",
        "Please explore to memorize the syntax/examples/built-in functions by calling certain GPT function(s). If this is not possible, please include the syntax and built-in functions in each prompt."
      ],
      "metadata": {
        "id": "3Kf1GK8LGWL0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install selenium"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1HSsrAhG3NT",
        "outputId": "853fd7a2-fced-470f-d77d-233f1bab4e94"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: selenium in /usr/local/lib/python3.12/dist-packages (4.38.0)\n",
            "Requirement already satisfied: urllib3<3.0,>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (2.5.0)\n",
            "Requirement already satisfied: trio<1.0,>=0.31.0 in /usr/local/lib/python3.12/dist-packages (from selenium) (0.32.0)\n",
            "Requirement already satisfied: trio-websocket<1.0,>=0.12.2 in /usr/local/lib/python3.12/dist-packages (from selenium) (0.12.2)\n",
            "Requirement already satisfied: certifi>=2025.10.5 in /usr/local/lib/python3.12/dist-packages (from selenium) (2025.10.5)\n",
            "Requirement already satisfied: typing_extensions<5.0,>=4.15.0 in /usr/local/lib/python3.12/dist-packages (from selenium) (4.15.0)\n",
            "Requirement already satisfied: websocket-client<2.0,>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from selenium) (1.9.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.31.0->selenium) (25.4.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.31.0->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.31.0->selenium) (3.11)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.31.0->selenium) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.31.0->selenium) (1.3.1)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.12/dist-packages (from trio-websocket<1.0,>=0.12.2->selenium) (1.2.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from wsproto>=0.14->trio-websocket<1.0,>=0.12.2->selenium) (0.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import time, tempfile, os, re, json, requests\n",
        "from typing import List, Set, Dict, Optional\n",
        "from bs4 import BeautifulSoup\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "import pandas as pd\n",
        "from openai import OpenAI\n",
        "\n",
        "# Global constants - - further automation by feeding a csv file input containing the info blow\n",
        "FRAMEWORK = \"Spring MVC\"\n",
        "TOPIC = \"Mismatch in @PathVariable declarations and usages\"\n",
        "NUM_RULES = 1\n",
        "CODEX5_SUGGESTING_NUM_RULES = 0\n",
        "SOURCE = \"https://www.jetbrains.com.cn/en-us/help/inspectopedia/MVCPathVariableInspection.html\"\n",
        "\n",
        "# Persist GPT-found URLs here so they’re excluded in future searches\n",
        "GPT_URLS_STORE = \"gpt4_found_urls.json\"\n",
        "\n",
        "# SerpAPI key (Colab)\n",
        "SERPAPI_API_KEY = userdata.get(\"SERPAPI_API_KEY\")\n",
        "\n",
        "def serpapi_google(q: str, num: int = 10) -> List[Dict]:\n",
        "    if not SERPAPI_API_KEY:\n",
        "        return []\n",
        "    try:\n",
        "        params = {\"engine\": \"google\", \"q\": q, \"api_key\": SERPAPI_API_KEY, \"num\": str(num)}\n",
        "        r = requests.get(\"https://serpapi.com/search\", params=params, timeout=20)\n",
        "        r.raise_for_status()\n",
        "        return r.json().get(\"organic_results\", [])\n",
        "    except Exception:\n",
        "        return []\n",
        "\n",
        "def locate_inspectopedia_url(framework: str, topic: str) -> Optional[str]:\n",
        "    \"\"\"\n",
        "    Use SerpAPI to find the Inspectopedia page for the given framework/topic.\n",
        "    Returns the first JetBrains.cn inspectopedia URL it finds.\n",
        "    \"\"\"\n",
        "    queries = [\n",
        "        f'site:jetbrains.com.cn Inspectopedia {FRAMEWORK} {TOPIC}',\n",
        "        f'site:jetbrains.com.cn help Inspectopedia {FRAMEWORK} {TOPIC}',\n",
        "    ]\n",
        "    print(queries)\n",
        "    for q in queries:\n",
        "        for item in serpapi_google(q, num=10):\n",
        "            url = item.get(\"link\", \"\")\n",
        "            if \"inspectopedia\" in url.lower() and \"jetbrains.com.cn\" in url.lower():\n",
        "                print(url)\n",
        "                return url\n",
        "    return None\n",
        "\n",
        "def isSOURCE(url: str) -> bool:\n",
        "    if locate_inspectopedia_url(FRAMEWORK, TOPIC) == SOURCE:\n",
        "        return url\n",
        "    else:\n",
        "        return SOURCE\n",
        "\n",
        "def get_jetbrains_description(url: str) -> str:\n",
        "    opts = Options()\n",
        "    opts.add_argument(\"--headless\")\n",
        "    opts.add_argument(\"--disable-gpu\")\n",
        "    opts.add_argument(\"--no-sandbox\")\n",
        "    opts.add_argument(\"--disable-dev-shm-usage\")\n",
        "    opts.add_argument(f\"--user-data-dir={tempfile.mkdtemp()}\")\n",
        "\n",
        "    driver = webdriver.Chrome(options=opts)\n",
        "    driver.get(url)\n",
        "    time.sleep(3)\n",
        "\n",
        "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
        "    driver.quit()\n",
        "\n",
        "    span = soup.find(\"span\", class_=\"sub-title sub-title--related-h1\")\n",
        "    if not span:\n",
        "        return \"(no span marker found)\"\n",
        "\n",
        "    text_parts = []\n",
        "    for sib in span.find_all_next():\n",
        "        if sib.name in (\"h2\", \"section\"):\n",
        "            break\n",
        "        if sib.name == \"p\":\n",
        "            text_parts.append(sib.get_text(\" \", strip=True))\n",
        "    return \" \".join(text_parts)\n",
        "\n"
      ],
      "metadata": {
        "id": "GcjiYs-ho_88"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the JetBrains inspection description\n",
        "CONTENT = get_jetbrains_description(SOURCE)"
      ],
      "metadata": {
        "id": "Gs-d3gm_Xmsc"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(CONTENT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lt2vsCgdXR0t",
        "outputId": "81bb32fb-4beb-41d4-bf35-1a54e807df45"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reports @PathVariable parameters that are declared in the method signature but are absent in the URL path or vice versa. The quick-fix adds the missing parameter. Example: After the quick-fix is applied the result looks like:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Newly generated rules expressed in RSL would use only these built-in functions for now to minizme the work of modification of the current engine, MeCheck.\n",
        "\n",
        "builtins_data = [\n",
        "    # Code-related\n",
        "    {\"name\":\"callExists\",\"category\":\"code\",\"purpose\":\"Check whether a specific call exists\",\"signature\":\"\"},\n",
        "    {\"name\":\"classExists\",\"category\":\"code\",\"purpose\":\"Check whether a class exists\",\"signature\":\"\"},\n",
        "    {\"name\":\"getArg\",\"category\":\"code\",\"purpose\":\"Get an argument from a call/method\",\"signature\":\"\"},\n",
        "    {\"name\":\"getClasses\",\"category\":\"code\",\"purpose\":\"Get a collection of classes\",\"signature\":\"\"},\n",
        "    {\"name\":\"getConstructors\",\"category\":\"code\",\"purpose\":\"Get constructors of a class\",\"signature\":\"\"},\n",
        "    {\"name\":\"getFamily\",\"category\":\"code\",\"purpose\":\"Get type hierarchy/family information\",\"signature\":\"\"},\n",
        "    {\"name\":\"getFields\",\"category\":\"code\",\"purpose\":\"Get fields of a class\",\"signature\":\"\"},\n",
        "    {\"name\":\"getFQN\",\"category\":\"code\",\"purpose\":\"Get fully qualified name\",\"signature\":\"\"},\n",
        "    {\"name\":\"getMethods\",\"category\":\"code\",\"purpose\":\"Get methods of a class\",\"signature\":\"\"},\n",
        "    {\"name\":\"getName\",\"category\":\"code\",\"purpose\":\"Get the simple name/identifier\",\"signature\":\"\"},\n",
        "    {\"name\":\"getReturnType\",\"category\":\"code\",\"purpose\":\"Get a method's return type\",\"signature\":\"\"},\n",
        "    {\"name\":\"getSN\",\"category\":\"code\",\"purpose\":\"Get simple name (SN)\",\"signature\":\"\"},\n",
        "    {\"name\":\"getType\",\"category\":\"code\",\"purpose\":\"Get type information\",\"signature\":\"\"},\n",
        "    {\"name\":\"hasField\",\"category\":\"code\",\"purpose\":\"Check whether a class has a specific field\",\"signature\":\"\"},\n",
        "    {\"name\":\"hasParam\",\"category\":\"code\",\"purpose\":\"Check whether a method has a specific parameter\",\"signature\":\"\"},\n",
        "    {\"name\":\"hasParamType\",\"category\":\"code\",\"purpose\":\"Check whether a method has a parameter of a given type\",\"signature\":\"\"},\n",
        "    {\"name\":\"indexInBound\",\"category\":\"code\",\"purpose\":\"Check whether an index is within bounds\",\"signature\":\"\"},\n",
        "    {\"name\":\"isIterable\",\"category\":\"code\",\"purpose\":\"Check whether a type is iterable\",\"signature\":\"\"},\n",
        "    {\"name\":\"isLibraryClass\",\"category\":\"code\",\"purpose\":\"Check whether the class comes from libraries\",\"signature\":\"\"},\n",
        "    {\"name\":\"isUniqueSN\",\"category\":\"code\",\"purpose\":\"Check whether the simple name is unique\",\"signature\":\"\"},\n",
        "    {\"name\":\"locateClassSN\",\"category\":\"code\",\"purpose\":\"Locate a class by simple name\",\"signature\":\"\"},\n",
        "    {\"name\":\"locateClassFQN\",\"category\":\"code\",\"purpose\":\"Locate a class by fully qualified name\",\"signature\":\"\"},\n",
        "\n",
        "    # Annotation-related\n",
        "    {\"name\":\"getAnnoAttr\",\"category\":\"annotation\",\"purpose\":\"Get an annotation attribute value\",\"signature\":\"\"},\n",
        "    {\"name\":\"getAnnoAttrNames\",\"category\":\"annotation\",\"purpose\":\"Get the set of annotation attribute names\",\"signature\":\"\"},\n",
        "    {\"name\":\"getAnnotated\",\"category\":\"annotation\",\"purpose\":\"Get elements annotated with a given annotation\",\"signature\":\"\"},\n",
        "    {\"name\":\"hasAnnotation\",\"category\":\"annotation\",\"purpose\":\"Check whether an element has a given annotation\",\"signature\":\"\"},\n",
        "    {\"name\":\"hasAnnoAttr\",\"category\":\"annotation\",\"purpose\":\"Check whether an annotation attribute exists\",\"signature\":\"\"},\n",
        "\n",
        "    # XML-related\n",
        "    {\"name\":\"elementExists\",\"category\":\"xml\",\"purpose\":\"Check whether an XML element exists\",\"signature\":\"\"},\n",
        "    {\"name\":\"getAttr\",\"category\":\"xml\",\"purpose\":\"Get an XML attribute value\",\"signature\":\"\"},\n",
        "    {\"name\":\"getAttrs\",\"category\":\"xml\",\"purpose\":\"Get a set of XML attributes\",\"signature\":\"\"},\n",
        "    {\"name\":\"getElms\",\"category\":\"xml\",\"purpose\":\"Get a set of XML elements\",\"signature\":\"\"},\n",
        "    {\"name\":\"getXMLs\",\"category\":\"xml\",\"purpose\":\"Get XML documents/fragments\",\"signature\":\"\"},\n",
        "    {\"name\":\"hasAttr\",\"category\":\"xml\",\"purpose\":\"Check whether an XML attribute exists\",\"signature\":\"\"},\n",
        "\n",
        "    # Miscellaneous\n",
        "    {\"name\":\"endsWith\",\"category\":\"misc\",\"purpose\":\"Check whether a string ends with a suffix\",\"signature\":\"\"},\n",
        "    {\"name\":\"isEmpty\",\"category\":\"misc\",\"purpose\":\"Check whether a string/collection is empty\",\"signature\":\"\"},\n",
        "    {\"name\":\"indexOf\",\"category\":\"misc\",\"purpose\":\"Return the index of a substring/element\",\"signature\":\"\"},\n",
        "    {\"name\":\"join\",\"category\":\"misc\",\"purpose\":\"Join/concatenate values\",\"signature\":\"\"},\n",
        "    {\"name\":\"pathExists\",\"category\":\"misc\",\"purpose\":\"Check whether a filesystem/project path exists\",\"signature\":\"\"},\n",
        "    {\"name\":\"substring\",\"category\":\"misc\",\"purpose\":\"Extract a substring\",\"signature\":\"\"},\n",
        "    {\"name\":\"startsWith\",\"category\":\"misc\",\"purpose\":\"Check whether a string starts with a prefix\",\"signature\":\"\"},\n",
        "    {\"name\":\"upperCase\",\"category\":\"misc\",\"purpose\":\"Convert a string to upper case\",\"signature\":\"\"},\n",
        "]\n",
        "\n",
        "builtins_df = pd.DataFrame(builtins_data)\n",
        "builtins_df\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rmt96UWopGpw",
        "outputId": "876a91f7-cfad-4137-96a8-1602f0cd17a9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                name    category  \\\n",
              "0         callExists        code   \n",
              "1        classExists        code   \n",
              "2             getArg        code   \n",
              "3         getClasses        code   \n",
              "4    getConstructors        code   \n",
              "5          getFamily        code   \n",
              "6          getFields        code   \n",
              "7             getFQN        code   \n",
              "8         getMethods        code   \n",
              "9            getName        code   \n",
              "10     getReturnType        code   \n",
              "11             getSN        code   \n",
              "12           getType        code   \n",
              "13          hasField        code   \n",
              "14          hasParam        code   \n",
              "15      hasParamType        code   \n",
              "16      indexInBound        code   \n",
              "17        isIterable        code   \n",
              "18    isLibraryClass        code   \n",
              "19        isUniqueSN        code   \n",
              "20     locateClassSN        code   \n",
              "21    locateClassFQN        code   \n",
              "22       getAnnoAttr  annotation   \n",
              "23  getAnnoAttrNames  annotation   \n",
              "24      getAnnotated  annotation   \n",
              "25     hasAnnotation  annotation   \n",
              "26       hasAnnoAttr  annotation   \n",
              "27     elementExists         xml   \n",
              "28           getAttr         xml   \n",
              "29          getAttrs         xml   \n",
              "30           getElms         xml   \n",
              "31           getXMLs         xml   \n",
              "32           hasAttr         xml   \n",
              "33          endsWith        misc   \n",
              "34           isEmpty        misc   \n",
              "35           indexOf        misc   \n",
              "36              join        misc   \n",
              "37        pathExists        misc   \n",
              "38         substring        misc   \n",
              "39        startsWith        misc   \n",
              "40         upperCase        misc   \n",
              "\n",
              "                                              purpose signature  \n",
              "0                Check whether a specific call exists            \n",
              "1                        Check whether a class exists            \n",
              "2                  Get an argument from a call/method            \n",
              "3                         Get a collection of classes            \n",
              "4                         Get constructors of a class            \n",
              "5               Get type hierarchy/family information            \n",
              "6                               Get fields of a class            \n",
              "7                            Get fully qualified name            \n",
              "8                              Get methods of a class            \n",
              "9                      Get the simple name/identifier            \n",
              "10                         Get a method's return type            \n",
              "11                               Get simple name (SN)            \n",
              "12                               Get type information            \n",
              "13         Check whether a class has a specific field            \n",
              "14    Check whether a method has a specific parameter            \n",
              "15  Check whether a method has a parameter of a gi...            \n",
              "16            Check whether an index is within bounds            \n",
              "17                   Check whether a type is iterable            \n",
              "18       Check whether the class comes from libraries            \n",
              "19            Check whether the simple name is unique            \n",
              "20                      Locate a class by simple name            \n",
              "21             Locate a class by fully qualified name            \n",
              "22                  Get an annotation attribute value            \n",
              "23          Get the set of annotation attribute names            \n",
              "24     Get elements annotated with a given annotation            \n",
              "25    Check whether an element has a given annotation            \n",
              "26       Check whether an annotation attribute exists            \n",
              "27                Check whether an XML element exists            \n",
              "28                         Get an XML attribute value            \n",
              "29                        Get a set of XML attributes            \n",
              "30                          Get a set of XML elements            \n",
              "31                        Get XML documents/fragments            \n",
              "32              Check whether an XML attribute exists            \n",
              "33          Check whether a string ends with a suffix            \n",
              "34         Check whether a string/collection is empty            \n",
              "35            Return the index of a substring/element            \n",
              "36                            Join/concatenate values            \n",
              "37     Check whether a filesystem/project path exists            \n",
              "38                                Extract a substring            \n",
              "39        Check whether a string starts with a prefix            \n",
              "40                     Convert a string to upper case            "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-22788a79-bc2e-4e15-b156-72849882f4aa\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>category</th>\n",
              "      <th>purpose</th>\n",
              "      <th>signature</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>callExists</td>\n",
              "      <td>code</td>\n",
              "      <td>Check whether a specific call exists</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>classExists</td>\n",
              "      <td>code</td>\n",
              "      <td>Check whether a class exists</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>getArg</td>\n",
              "      <td>code</td>\n",
              "      <td>Get an argument from a call/method</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>getClasses</td>\n",
              "      <td>code</td>\n",
              "      <td>Get a collection of classes</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>getConstructors</td>\n",
              "      <td>code</td>\n",
              "      <td>Get constructors of a class</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>getFamily</td>\n",
              "      <td>code</td>\n",
              "      <td>Get type hierarchy/family information</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>getFields</td>\n",
              "      <td>code</td>\n",
              "      <td>Get fields of a class</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>getFQN</td>\n",
              "      <td>code</td>\n",
              "      <td>Get fully qualified name</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>getMethods</td>\n",
              "      <td>code</td>\n",
              "      <td>Get methods of a class</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>getName</td>\n",
              "      <td>code</td>\n",
              "      <td>Get the simple name/identifier</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>getReturnType</td>\n",
              "      <td>code</td>\n",
              "      <td>Get a method's return type</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>getSN</td>\n",
              "      <td>code</td>\n",
              "      <td>Get simple name (SN)</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>getType</td>\n",
              "      <td>code</td>\n",
              "      <td>Get type information</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>hasField</td>\n",
              "      <td>code</td>\n",
              "      <td>Check whether a class has a specific field</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>hasParam</td>\n",
              "      <td>code</td>\n",
              "      <td>Check whether a method has a specific parameter</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>hasParamType</td>\n",
              "      <td>code</td>\n",
              "      <td>Check whether a method has a parameter of a gi...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>indexInBound</td>\n",
              "      <td>code</td>\n",
              "      <td>Check whether an index is within bounds</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>isIterable</td>\n",
              "      <td>code</td>\n",
              "      <td>Check whether a type is iterable</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>isLibraryClass</td>\n",
              "      <td>code</td>\n",
              "      <td>Check whether the class comes from libraries</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>isUniqueSN</td>\n",
              "      <td>code</td>\n",
              "      <td>Check whether the simple name is unique</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>locateClassSN</td>\n",
              "      <td>code</td>\n",
              "      <td>Locate a class by simple name</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>locateClassFQN</td>\n",
              "      <td>code</td>\n",
              "      <td>Locate a class by fully qualified name</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>getAnnoAttr</td>\n",
              "      <td>annotation</td>\n",
              "      <td>Get an annotation attribute value</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>getAnnoAttrNames</td>\n",
              "      <td>annotation</td>\n",
              "      <td>Get the set of annotation attribute names</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>getAnnotated</td>\n",
              "      <td>annotation</td>\n",
              "      <td>Get elements annotated with a given annotation</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>hasAnnotation</td>\n",
              "      <td>annotation</td>\n",
              "      <td>Check whether an element has a given annotation</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>hasAnnoAttr</td>\n",
              "      <td>annotation</td>\n",
              "      <td>Check whether an annotation attribute exists</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>elementExists</td>\n",
              "      <td>xml</td>\n",
              "      <td>Check whether an XML element exists</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>getAttr</td>\n",
              "      <td>xml</td>\n",
              "      <td>Get an XML attribute value</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>getAttrs</td>\n",
              "      <td>xml</td>\n",
              "      <td>Get a set of XML attributes</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>getElms</td>\n",
              "      <td>xml</td>\n",
              "      <td>Get a set of XML elements</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>getXMLs</td>\n",
              "      <td>xml</td>\n",
              "      <td>Get XML documents/fragments</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>hasAttr</td>\n",
              "      <td>xml</td>\n",
              "      <td>Check whether an XML attribute exists</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>endsWith</td>\n",
              "      <td>misc</td>\n",
              "      <td>Check whether a string ends with a suffix</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>isEmpty</td>\n",
              "      <td>misc</td>\n",
              "      <td>Check whether a string/collection is empty</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>indexOf</td>\n",
              "      <td>misc</td>\n",
              "      <td>Return the index of a substring/element</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>join</td>\n",
              "      <td>misc</td>\n",
              "      <td>Join/concatenate values</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>pathExists</td>\n",
              "      <td>misc</td>\n",
              "      <td>Check whether a filesystem/project path exists</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>substring</td>\n",
              "      <td>misc</td>\n",
              "      <td>Extract a substring</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>startsWith</td>\n",
              "      <td>misc</td>\n",
              "      <td>Check whether a string starts with a prefix</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>upperCase</td>\n",
              "      <td>misc</td>\n",
              "      <td>Convert a string to upper case</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-22788a79-bc2e-4e15-b156-72849882f4aa')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-22788a79-bc2e-4e15-b156-72849882f4aa button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-22788a79-bc2e-4e15-b156-72849882f4aa');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-fd107fb2-21dd-4d1d-9d47-7aba03ceedba\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fd107fb2-21dd-4d1d-9d47-7aba03ceedba')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-fd107fb2-21dd-4d1d-9d47-7aba03ceedba button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_d069cb48-e5ed-4d90-8b86-18d0753bb9ea\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('builtins_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_d069cb48-e5ed-4d90-8b86-18d0753bb9ea button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('builtins_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "builtins_df",
              "summary": "{\n  \"name\": \"builtins_df\",\n  \"rows\": 41,\n  \"fields\": [\n    {\n      \"column\": \"name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 41,\n        \"samples\": [\n          \"getAnnotated\",\n          \"hasField\",\n          \"getMethods\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"annotation\",\n          \"misc\",\n          \"code\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"purpose\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 41,\n        \"samples\": [\n          \"Get elements annotated with a given annotation\",\n          \"Check whether a class has a specific field\",\n          \"Get methods of a class\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"signature\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Text Registry (single source of truth) ===\n",
        "RSL_SYNTAX = r\"\"\"Specification := Rule Id Body\n",
        "Body := '{' Stmt Stmt* '}'\n",
        "Stmt := ForStmt | IfStmt | AssertStmt | DeclStmt ';'\n",
        "\n",
        "ForStmt := 'for' '(' Type Id 'in' Exp ')' Body\n",
        "IfStmt := 'if' '(' Exp ')' Body\n",
        "\n",
        "AssertStmt := 'assert' '(' Exp ')' '{' MsgStmt ';' '}'\n",
        "MsgStmt := 'msg' '(' ',' SimExp (',' SimExp)* ')'\n",
        "\n",
        "DeclStmt := Type Id '=' Exp\n",
        "\n",
        "Exp := SimExp\n",
        "     | SimExp AND Exp\n",
        "     | SimExp OR  Exp\n",
        "     | NOT Exp\n",
        "\n",
        "SimExp := Id\n",
        "        | Lit\n",
        "        | FunctionCall\n",
        "        | '(' Exp ')'\n",
        "        | FunctionCall '==' SimExp\n",
        "        | exists '(' Type Id in Exp ')' '(' Exp ')'\n",
        "\n",
        "Type := '⟨' Id '⟩' | file | class | method | field | String\n",
        "Lit := StringLit | CharLit | IntLit | FloatLit\n",
        "FunctionCall := Id '(' Params ')'\n",
        "Params := SimExp (',' SimExp)*\"\"\"\n",
        "\n",
        "# Sample Rules are Rule #1, #3, and #5. If these change into some other subset, the output of newly generated rule may differ.\n",
        "\n",
        "RSL_EXAMPLE_RULES = r\"\"\"// Rule 1 — bean-class-exists\n",
        "Rule bean-class-exists {\n",
        "  for (file xml in getXMLs()) {\n",
        "    if (elementExists(xml, \"<bean>\")) {\n",
        "      for (<bean> bean in getElms(xml, \"<bean>\")) {\n",
        "        String beanClassFQN = getAttr(bean, \"class\");\n",
        "        if (NOT isEmpty(beanClassFQN)) {\n",
        "          assert ( classExists(beanClassFQN) OR isLibraryClass(beanClassFQN) ) {\n",
        "            msg(\"Bean class: %s mentioned in bean: %s, does not exist\",\n",
        "                beanClassFQN, getName(bean));\n",
        "          }\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "// Rule 3 — constructor-arg-name-field-map\n",
        "Rule constructor-arg-name-field-map {\n",
        "  for (file xml in getXMLs()) {\n",
        "    if (elementExists(xml, \"<bean>\")) {\n",
        "      for (<bean> bean in getElms(xml, \"<bean>\")) {\n",
        "        String beanClassFQN = getAttr(bean, \"class\");\n",
        "        if (classExists(beanClassFQN)) {\n",
        "          class c = locateClassFQN(beanClassFQN);\n",
        "          for (<constructor-arg> constructor_arg in getElms(bean, \"<constructor-arg>\")) {\n",
        "            String arg_name = getAttr(constructor_arg, \"name\");\n",
        "            if (NOT isEmpty(arg_name)) {\n",
        "              assert ( exists(method con in getConstructors(c)) ( hasParam(con, arg_name) ) ) {\n",
        "                msg(\"The name of <constructor-arg>: %s in bean: %s does not correspond to any constructor parameter in class: %s\",\n",
        "                    arg_name, getName(bean), getFQN(c));\n",
        "              }\n",
        "            }\n",
        "          }\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "// Rule 5 — constructor-index-out-of-bound\n",
        "Rule constructor-index-out-of-bound {\n",
        "  for (file xml in getXMLs()) {\n",
        "    if (elementExists(xml, \"<bean>\")) {\n",
        "      for (<bean> bean in getElms(xml, \"<bean>\")) {\n",
        "        String beanClassFQN = getAttr(bean, \"class\");\n",
        "        if (classExists(beanClassFQN)) {\n",
        "          class c = locateClassFQN(beanClassFQN);\n",
        "          for (<constructor-arg> constructor_arg in getElms(bean, \"<constructor-arg>\")) {\n",
        "            if (hasAttr(constructor_arg, \"index\")) {\n",
        "              String arg_idx = getAttr(constructor_arg, \"index\");\n",
        "              assert ( exists(method constructor in getConstructors(c)) ( indexInBound(constructor, arg_idx) ) ) {\n",
        "                msg(\"Constructor index: %s of bean for class: %s in xml: %s is out of bound\",\n",
        "                    arg_idx, getFQN(c), getName(xml));\n",
        "              }\n",
        "            }\n",
        "          }\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}\"\"\"\n"
      ],
      "metadata": {
        "id": "34nShSNJyNbE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keyword_message = {\"role\": \"user\",\n",
        "                   \"content\": f'''\n",
        "                    Context:\n",
        "                    Notice the inspection from JetBrains's Inspectopedia relating to\n",
        "                    the {FRAMEWORK} framework or library -\n",
        "                    {TOPIC}.\n",
        "                    Additionally, here is the source for the topic:\n",
        "                    {SOURCE}\n",
        "\n",
        "                    Goal:\n",
        "                    Grab 3 keywords from this topic that would be helpful for\n",
        "                    searching third party sources relating to this specific inspection.\n",
        "                    Have the keywords related soley on the framework and topic mentioned\n",
        "                    rather than the JetBrains or Inspectopedia.\n",
        "                    Return ONLY the keywords found with no explanation or additional\n",
        "                    content, return each keyword as a single word or at least without\n",
        "                    whitespace, and return the keywords as a list in the format:\n",
        "                    \"[keyword_a, keyword_b, keyword_c]\"\n",
        "                    '''}\n",
        "\n",
        "def get_topic_keywords():\n",
        "  os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
        "  client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
        "  response = client.chat.completions.create(\n",
        "      model=\"gpt-5\",\n",
        "      messages=[keyword_message]\n",
        "  )\n",
        "\n",
        "  return response.choices[0].message.content.strip()\n",
        "\n",
        "KEYWORDS = get_topic_keywords()\n",
        "print(KEYWORDS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqG-6kW3inob",
        "outputId": "df65e22f-2fee-4828-8854-eda68a398190"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[PathVariable, RequestMapping, URITemplate]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# After many trials, this prompt is able to locate relevant 3rd-party web page(s) and confirms that the new rule is aligned with those located 3rd-party web page(s).\n",
        "# GPT-4 is the intial rule creator, validator (Pre- and Post- before/after locating the most relevant 3rd-party web page(s))\n",
        "\n",
        "PROMPT_ORIGINAL_TMPL = r\"\"\"You are an expert in metadata used in the {{FRAMEWORK}} library/framework.\n",
        "Here is the core syntax of the language you will translate in plain English\n",
        "natural language per rule. This is the core syntax of Rule-Specific Language (RSL):\n",
        "{{RSL_SYNTAX}} \\Here is the currently built-in functions: {{BUILTIN_REFERENCE}}\n",
        "\\Here are three example rules expressed in RSL: {{EXAMPLE_RULES}}\n",
        "\\As sample rules, I shared three rules with you.\n",
        "\\Your job is to create one rule that corresponds to the topic {{TOPIC}}\n",
        "with the following content:\n",
        "  {{CONTENT}}.\n",
        "\n",
        "Like the sample rules, it should be described following the syntax of RSL. You briefly describe what the new rule checks. The new rule must use only the built-in functions.\n",
        "This means that you should not introduce new built-in functions while creating a new rule corresponding to the topic and content. In the new_built-in functions_explanation column, \\\n",
        "provide names of all built-in functions used in the new rule after confirming that no new functions were introduced. Also, there should not be any comments or BOM (byte order mark) to save the rule in a txt file.\n",
        "You as a model should validate the new rule using your knowledge according to the content and topic addressed in the JetBrains web page as a source URL.\n",
        "\\Then, locate the most relevant, at most, two 3rd-party web pages that address the the topic, content, and the generated rule in terms of metadata-related bugs.\n",
        "Provide a breif summary per the 3rd-party web page content in one column together. Finally, provide a post-model validation based on generated rule and the located most relevant 3rd-party web page(s).\n",
        "Prioritize finding 3rd-party web pages with at least one of the following keywords in the URLs to ensure relevancy: {{KEYWORDS}}.\n",
        "The keywords found in the URLS do not have to be exact matches to the keywords in the list.\n",
        "\n",
        "Return the output **strictly** as a valid JSON array, not text, not markdown,\n",
        "not explanation.\n",
        "\n",
        "You must NOT include any text, commentary, or code fences (like ```).\n",
        "You must NOT prepend or append any text before or after the JSON array.\n",
        "\n",
        "Each JSON object must include exactly these fields:\n",
        "[\n",
        "  \"framework\",\n",
        "  \"source URL (JetBrains web page)\"\n",
        "  \"brief_description of the content in the source URL\",\n",
        "  \"GPT-4 generated_rule\",\n",
        "  \"generated_rule_explanation from GPT-4\",\n",
        "  \"new_built-in_functions_explanation if any\",\n",
        "  \"PRE_model_validation\",\n",
        "  \"3rd-party most relevant URLs and summary for each URL\",\n",
        "  \"POST_model validation\",\n",
        "\n",
        "]\n",
        "\n",
        "The output must start with \"[\" and end with \"]\".\n",
        "If you cannot find information for any field, use an empty string (\"\").\"\"\""
      ],
      "metadata": {
        "id": "fwS_1QVd5yLp"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def render_builtin_reference(df):\n",
        "    return \"\\n\".join(f\"- {row['name']}\" for _, row in df.iterrows())"
      ],
      "metadata": {
        "id": "zn3l-kLP8mrz"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _mk_source_suffix(source: str | None) -> str:\n",
        "    if not source or str(source).strip() == \"\":\n",
        "        return \"\"\n",
        "    return f\" (Reference source: {source})\"  # ✅ For now source is hard-coded\n",
        "\n",
        "\n",
        "def render_original_prompt(\n",
        "    framework: str = FRAMEWORK,\n",
        "    num_rules: int = NUM_RULES,\n",
        "    topic: str = TOPIC,\n",
        "    source: str | None = SOURCE,\n",
        "    template_text: str = PROMPT_ORIGINAL_TMPL,\n",
        "    content: str = CONTENT,\n",
        "    keywords: str = KEYWORDS\n",
        "):\n",
        "    \"\"\"Splicing Final Prompt\"\"\"\n",
        "    return (template_text\n",
        "            .replace(\"{{RSL_SYNTAX}}\", RSL_SYNTAX)\n",
        "            .replace(\"{{EXAMPLE_RULES}}\", RSL_EXAMPLE_RULES)\n",
        "            .replace(\"{{BUILTIN_REFERENCE}}\", render_builtin_reference(builtins_df))\n",
        "            .replace(\"{{FRAMEWORK}}\", framework)\n",
        "            .replace(\"{{SOURCE_SUFFIX}}\", _mk_source_suffix(source))\n",
        "            .replace(\"{{NUM_RULES}}\", str(num_rules))\n",
        "            .replace(\"{{TOPIC}}\", topic)\n",
        "            .replace(\"{{CONTENT}}\", content)\n",
        "            .replace(\"{{KEYWORDS}}\", keywords))\n",
        "\n",
        "# === [Block 2] Prompt Generation Combining All Info  ===\n",
        "final_prompt = render_original_prompt()\n",
        "\n",
        "print(final_prompt)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QJimfY-5Tef",
        "outputId": "1087ca13-23b1-4819-9e56-acf31327b0b9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are an expert in metadata used in the Spring MVC library/framework.\n",
            "Here is the core syntax of the language you will translate in plain English\n",
            "natural language per rule. This is the core syntax of Rule-Specific Language (RSL):\n",
            "Specification := Rule Id Body\n",
            "Body := '{' Stmt Stmt* '}'\n",
            "Stmt := ForStmt | IfStmt | AssertStmt | DeclStmt ';'\n",
            "\n",
            "ForStmt := 'for' '(' Type Id 'in' Exp ')' Body\n",
            "IfStmt := 'if' '(' Exp ')' Body\n",
            "\n",
            "AssertStmt := 'assert' '(' Exp ')' '{' MsgStmt ';' '}'\n",
            "MsgStmt := 'msg' '(' ',' SimExp (',' SimExp)* ')'\n",
            "\n",
            "DeclStmt := Type Id '=' Exp\n",
            "\n",
            "Exp := SimExp\n",
            "     | SimExp AND Exp\n",
            "     | SimExp OR  Exp\n",
            "     | NOT Exp\n",
            "\n",
            "SimExp := Id\n",
            "        | Lit\n",
            "        | FunctionCall\n",
            "        | '(' Exp ')'\n",
            "        | FunctionCall '==' SimExp\n",
            "        | exists '(' Type Id in Exp ')' '(' Exp ')'\n",
            "\n",
            "Type := '⟨' Id '⟩' | file | class | method | field | String\n",
            "Lit := StringLit | CharLit | IntLit | FloatLit\n",
            "FunctionCall := Id '(' Params ')'\n",
            "Params := SimExp (',' SimExp)* \\Here is the currently built-in functions: - callExists\n",
            "- classExists\n",
            "- getArg\n",
            "- getClasses\n",
            "- getConstructors\n",
            "- getFamily\n",
            "- getFields\n",
            "- getFQN\n",
            "- getMethods\n",
            "- getName\n",
            "- getReturnType\n",
            "- getSN\n",
            "- getType\n",
            "- hasField\n",
            "- hasParam\n",
            "- hasParamType\n",
            "- indexInBound\n",
            "- isIterable\n",
            "- isLibraryClass\n",
            "- isUniqueSN\n",
            "- locateClassSN\n",
            "- locateClassFQN\n",
            "- getAnnoAttr\n",
            "- getAnnoAttrNames\n",
            "- getAnnotated\n",
            "- hasAnnotation\n",
            "- hasAnnoAttr\n",
            "- elementExists\n",
            "- getAttr\n",
            "- getAttrs\n",
            "- getElms\n",
            "- getXMLs\n",
            "- hasAttr\n",
            "- endsWith\n",
            "- isEmpty\n",
            "- indexOf\n",
            "- join\n",
            "- pathExists\n",
            "- substring\n",
            "- startsWith\n",
            "- upperCase\n",
            "\\Here are three example rules expressed in RSL: // Rule 1 — bean-class-exists\n",
            "Rule bean-class-exists {\n",
            "  for (file xml in getXMLs()) {\n",
            "    if (elementExists(xml, \"<bean>\")) {\n",
            "      for (<bean> bean in getElms(xml, \"<bean>\")) {\n",
            "        String beanClassFQN = getAttr(bean, \"class\");\n",
            "        if (NOT isEmpty(beanClassFQN)) {\n",
            "          assert ( classExists(beanClassFQN) OR isLibraryClass(beanClassFQN) ) {\n",
            "            msg(\"Bean class: %s mentioned in bean: %s, does not exist\",\n",
            "                beanClassFQN, getName(bean));\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "// Rule 3 — constructor-arg-name-field-map\n",
            "Rule constructor-arg-name-field-map {\n",
            "  for (file xml in getXMLs()) {\n",
            "    if (elementExists(xml, \"<bean>\")) {\n",
            "      for (<bean> bean in getElms(xml, \"<bean>\")) {\n",
            "        String beanClassFQN = getAttr(bean, \"class\");\n",
            "        if (classExists(beanClassFQN)) {\n",
            "          class c = locateClassFQN(beanClassFQN);\n",
            "          for (<constructor-arg> constructor_arg in getElms(bean, \"<constructor-arg>\")) {\n",
            "            String arg_name = getAttr(constructor_arg, \"name\");\n",
            "            if (NOT isEmpty(arg_name)) {\n",
            "              assert ( exists(method con in getConstructors(c)) ( hasParam(con, arg_name) ) ) {\n",
            "                msg(\"The name of <constructor-arg>: %s in bean: %s does not correspond to any constructor parameter in class: %s\",\n",
            "                    arg_name, getName(bean), getFQN(c));\n",
            "              }\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "// Rule 5 — constructor-index-out-of-bound\n",
            "Rule constructor-index-out-of-bound {\n",
            "  for (file xml in getXMLs()) {\n",
            "    if (elementExists(xml, \"<bean>\")) {\n",
            "      for (<bean> bean in getElms(xml, \"<bean>\")) {\n",
            "        String beanClassFQN = getAttr(bean, \"class\");\n",
            "        if (classExists(beanClassFQN)) {\n",
            "          class c = locateClassFQN(beanClassFQN);\n",
            "          for (<constructor-arg> constructor_arg in getElms(bean, \"<constructor-arg>\")) {\n",
            "            if (hasAttr(constructor_arg, \"index\")) {\n",
            "              String arg_idx = getAttr(constructor_arg, \"index\");\n",
            "              assert ( exists(method constructor in getConstructors(c)) ( indexInBound(constructor, arg_idx) ) ) {\n",
            "                msg(\"Constructor index: %s of bean for class: %s in xml: %s is out of bound\",\n",
            "                    arg_idx, getFQN(c), getName(xml));\n",
            "              }\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\\As sample rules, I shared three rules with you.\n",
            "\\Your job is to create one rule that corresponds to the topic Mismatch in @PathVariable declarations and usages\n",
            "with the following content:\n",
            "  Reports @PathVariable parameters that are declared in the method signature but are absent in the URL path or vice versa. The quick-fix adds the missing parameter. Example: After the quick-fix is applied the result looks like:.\n",
            "\n",
            "Like the sample rules, it should be described following the syntax of RSL. You briefly describe what the new rule checks. The new rule must use only the built-in functions.\n",
            "This means that you should not introduce new built-in functions while creating a new rule corresponding to the topic and content. In the new_built-in functions_explanation column, \\\n",
            "provide names of all built-in functions used in the new rule after confirming that no new functions were introduced. Also, there should not be any comments or BOM (byte order mark) to save the rule in a txt file.\n",
            "You as a model should validate the new rule using your knowledge according to the content and topic addressed in the JetBrains web page as a source URL.\n",
            "\\Then, locate the most relevant, at most, two 3rd-party web pages that address the the topic, content, and the generated rule in terms of metadata-related bugs.\n",
            "Provide a breif summary per the 3rd-party web page content in one column together. Finally, provide a post-model validation based on generated rule and the located most relevant 3rd-party web page(s).\n",
            "Prioritize finding 3rd-party web pages with at least one of the following keywords in the URLs to ensure relevancy: [PathVariable, RequestMapping, URITemplate].\n",
            "The keywords found in the URLS do not have to be exact matches to the keywords in the list.\n",
            "\n",
            "Return the output **strictly** as a valid JSON array, not text, not markdown,\n",
            "not explanation.\n",
            "\n",
            "You must NOT include any text, commentary, or code fences (like ```).\n",
            "You must NOT prepend or append any text before or after the JSON array.\n",
            "\n",
            "Each JSON object must include exactly these fields:\n",
            "[\n",
            "  \"framework\",\n",
            "  \"source URL (JetBrains web page)\"\n",
            "  \"brief_description of the content in the source URL\",\n",
            "  \"GPT-4 generated_rule\",\n",
            "  \"generated_rule_explanation from GPT-4\",\n",
            "  \"new_built-in_functions_explanation if any\",\n",
            "  \"PRE_model_validation\",\n",
            "  \"3rd-party most relevant URLs and summary for each URL\",\n",
            "  \"POST_model validation\",\n",
            "\n",
            "]\n",
            "\n",
            "The output must start with \"[\" and end with \"]\".\n",
            "If you cannot find information for any field, use an empty string (\"\").\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Config (Drive paths are just examples) ---\n",
        "CSV_PATH = \"/content/original_rsl_generated_rules.csv\"\n",
        "newRULE_PATH = \"/content/new_GPT_4_generated_rule.txt\"\n",
        "newRULE_EXPLANATIONS_PATH = \"/content/new_generated_rule_explanation.json\"\n",
        "GPT4_RULE_DESCRIPTION_PATH = \"/content/gpt4_rule_description_scraped_content.json\"\n",
        "\n",
        "EXPECTED_COLUMNS = [\n",
        "    \"framework\",\n",
        "    \"source URL (JetBrains web page)\",\n",
        "    \"brief_description of the content in the source URL\",\n",
        "    \"GPT-4 generated_rule\",\n",
        "    \"generated_rule_explanation from GPT-4\",\n",
        "    \"new_built-in_functions_explanation if any\",\n",
        "    \"PRE_model_validation\",\n",
        "    \"3rd-party most relevant URLs and summary for each URL\",\n",
        "    \"POST_model validation\",\n",
        "]\n",
        "\n",
        "# --- OpenAI client (no explicit temperature; model default applies) ---\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
        "client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4\",\n",
        "    temperature=0,\n",
        "    messages=[{\"role\": \"user\", \"content\": final_prompt}]\n",
        ")\n",
        "\n",
        "raw = response.choices[0].message.content.strip()\n",
        "print(\"Returned data preview:\\n\", raw[:500])\n",
        "rules = json.loads(raw)\n",
        "\n",
        "# --- Normalize to your schema (fill missing fields with empty strings) ---\n",
        "def coerce_to_schema(item: dict) -> dict:\n",
        "    # Try to map common alternative keys if your prompt returns slightly different names\n",
        "    aliases = {\n",
        "        \"framework\": [\"framework\"],\n",
        "        \"source URL (JetBrains web page)\": [\"source_url\", \"source URL\", \"jetbrains_source\", \"jetbrains_url\"],\n",
        "        \"brief_description of the content in the source URL\": [\"brief_description\", \"brief description\", \"source_brief\"],\n",
        "        \"GPT-4 generated_rule\": [\"generated_rule\", \"rule\", \"gpt4_rule\"],\n",
        "        \"generated_rule_explanation from GPT-4\": [\"generated_rule_explanation\", \"rule_explanation\", \"gpt4_rule_explanation\"],\n",
        "        \"new_built-in_functions_explanation if any\": [\"new_built_in_functions_explanation\", \"new_built-in_functions_explanation\", \"new_functions_note\"],\n",
        "        \"PRE_model_validation\": [\"pre_model_validation\", \"pre_validation\"],\n",
        "        \"3rd-party most relevant URLs and summary for each URL\": [\"third_party_urls_and_summaries\", \"3rd_party_urls_summaries\"],\n",
        "        \"POST_model validation\": [\"post_model_validation\", \"post_validation\"],\n",
        "    }\n",
        "\n",
        "    out = {}\n",
        "    for col in EXPECTED_COLUMNS:\n",
        "        val = \"\"\n",
        "        if isinstance(item, dict):\n",
        "            if col in item:\n",
        "                val = item[col]\n",
        "            else:\n",
        "                # look for an alias key\n",
        "                for alt in aliases.get(col, []):\n",
        "                    if alt in item:\n",
        "                        val = item[alt]\n",
        "                        break\n",
        "        out[col] = val if val is not None else \"\"\n",
        "    return out\n",
        "\n",
        "rows = [coerce_to_schema(x if isinstance(x, dict) else {}) for x in (rules if isinstance(rules, list) else [rules])]\n",
        "\n",
        "df = pd.DataFrame(rows, columns=EXPECTED_COLUMNS)\n",
        "\n",
        "# --- Save column “GPT-4 generated_rule” to TXT (one per line) ---\n",
        "generated_rules_txt = [str(x).strip() for x in df[\"GPT-4 generated_rule\"].fillna(\"\")]\n",
        "with open(newRULE_PATH, \"w\", encoding=\"utf-8\") as f:\n",
        "    for line in generated_rules_txt:\n",
        "        if line:\n",
        "            f.write(line + \"\\n\")\n",
        "print(f\"✅ Saved {len([x for x in generated_rules_txt if x])} rules to {newRULE_PATH}\")\n",
        "\n",
        "# --- Save column “generated_rule_explanation from GPT-4” to JSON (list of strings) ---\n",
        "\n",
        "generated_explanations = [str(x).strip() for x in df[\"generated_rule_explanation from GPT-4\"].fillna(\"\") if str(x).strip()]\n",
        "single_explanation = generated_explanations[0] if generated_explanations else \"\"\n",
        "try:\n",
        "    os.makedirs(os.path.dirname(newRULE_EXPLANATIONS_PATH), exist_ok=True)\n",
        "    with open(newRULE_EXPLANATIONS_PATH, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(\n",
        "            {\"new_generated_rule_explanation\": single_explanation},\n",
        "            f,\n",
        "            ensure_ascii=False,\n",
        "            indent=2\n",
        "        )\n",
        "    print(f\"✅ Saved new_generated_rule_explanation to {newRULE_EXPLANATIONS_PATH}\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Failed to save JSON: {e}\")\n",
        "\n",
        "with open(newRULE_EXPLANATIONS_PATH, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(generated_explanations, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "try:\n",
        "    os.makedirs(os.path.dirname(newRULE_EXPLANATIONS_PATH), exist_ok=True)\n",
        "    with open(newRULE_EXPLANATIONS_PATH, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(\n",
        "            {\"new_generated_rule_explanation\": single_explanation},\n",
        "            f,\n",
        "            ensure_ascii=False,\n",
        "            indent=2\n",
        "        )\n",
        "    print(f\"✅ Saved new_generated_rule_explanation to {newRULE_EXPLANATIONS_PATH}\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Failed to save JSON: {e}\")\n",
        "\n",
        "\n",
        "\n",
        "def load_new_rule_explanation(path: str = GPT4_RULE_DESCRIPTION_PATH) -> str:\n",
        "    \"\"\"\n",
        "    Loads the previously saved GPT-5 rule description for contextual use in SerpAPI searches.\n",
        "    Returns an empty string if none exists or file is corrupted.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(path):\n",
        "        print(\"⚠️ No saved GPT-4 rule description found.\")\n",
        "        return \"\"\n",
        "    try:\n",
        "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "            data = json.load(f)\n",
        "        return data.get(\"jetbrains_scraped_rule_description\", \"\")\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Failed to load saved description: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "def load_gpt4_rule_description(path: str = newRULE_EXPLANATIONS_PATH) -> str:\n",
        "    \"\"\"\n",
        "    Loads the new-GPT-4-generated rule explanation to provide context to SerpAPI later.\n",
        "    Returns an empty string if none exists or file is corrupted.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(path):\n",
        "        print(\"⚠️ No new-GPT-4 rule explanation found.\")\n",
        "        return \"\"\n",
        "    try:\n",
        "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "            data = json.load(f)\n",
        "        return data.get(\"new_generated_rule_explanation\", \"\")\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Failed to load saved description: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "\n",
        "# Step 2: Load later (e.g., in a new session)\n",
        "loaded_text = load_new_rule_explanation(GPT4_RULE_DESCRIPTION_PATH)\n",
        "print(\"\\n--- Loaded back from JSON scraped from JetBrains  ---\\n\")\n",
        "print(loaded_text[:500], \"...\")\n",
        "\n",
        "# Step 3: Load later (e.g., in a new session)\n",
        "loaded_text1 = load_gpt4_rule_description(newRULE_EXPLANATIONS_PATH)\n",
        "print(\"\\n--- Loaded back from JSON from gpt4_rule_explanation ---\\n\")\n",
        "print(loaded_text1[:500], \"...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6IlUuOmRvEM",
        "outputId": "400e8ac1-0b09-426b-bf24-2995abbcd66b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Returned data preview:\n",
            " [\n",
            "  {\n",
            "    \"framework\": \"Spring MVC\",\n",
            "    \"source URL (JetBrains web page)\": \"https://www.jetbrains.com/help/idea/spring-support.html\",\n",
            "    \"brief_description of the content in the source URL\": \"The JetBrains web page provides a comprehensive guide on Spring support in IntelliJ IDEA. It covers various aspects of Spring support, including navigation, coding assistance, data access, Spring AOP, Spring MVC, Spring Boot, and others. The page also provides information on how to enable Spring support i\n",
            "✅ Saved 1 rules to /content/new_GPT_4_generated_rule.txt\n",
            "✅ Saved new_generated_rule_explanation to /content/new_generated_rule_explanation.json\n",
            "✅ Saved new_generated_rule_explanation to /content/new_generated_rule_explanation.json\n",
            "⚠️ No saved GPT-4 rule description found.\n",
            "\n",
            "--- Loaded back from JSON scraped from JetBrains  ---\n",
            "\n",
            " ...\n",
            "\n",
            "--- Loaded back from JSON from gpt4_rule_explanation ---\n",
            "\n",
            "The rule 'pathVariable-mismatch' checks for mismatches between @PathVariable parameters declared in the method signature and those used in the URL path. It iterates over all classes and their methods. If a method has the @RequestMapping annotation, it retrieves the URL path. Then, for each field in the method, if it has the @PathVariable annotation, it checks if the variable name is present in the URL path. If not, it raises an error message. Similarly, it checks for each variable in the URL pat ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#--- Finally, save the full normalized CSV ---\n",
        "df.to_csv(CSV_PATH, index=False)\n",
        "print(f\"✅ Saved normalized data to {CSV_PATH}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZdAfjRcZt6g",
        "outputId": "c4d9a9f1-cb49-4edc-e0d4-4e3428ebdd7d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved normalized data to /content/original_rsl_generated_rules.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths & column name that should be excluded for SerpAPI search\n",
        "CSV_PATH = \"/content/original_rsl_generated_rules.csv\"\n",
        "CSV_URLS_COLUMN = \"3rd-party most relevant URLs and summary for each URL\"\n",
        "\n",
        "EXCLUDED_DOMAINS = {\n",
        "    \"jetbrains.com\",\n",
        "    \"www.jetbrains.com\",\n",
        "    \"jetbrains.com.cn\",\n",
        "    \"www.jetbrains.com.cn\",\n",
        "    \"example.com\",\n",
        "    \"example.org\"\n",
        "}\n",
        "\n",
        "# URL extractor\n",
        "_URL_RE = re.compile(r\"https?://[^\\s)>\\]}\\\"']+\", re.IGNORECASE)\n",
        "\n",
        "def _filter_real_urls(urls: Set[str]) -> Set[str]:\n",
        "    \"\"\"Remove JetBrains and example/test domains.\"\"\"\n",
        "    cleaned = set()\n",
        "    for url in urls:\n",
        "        lowered = url.lower()\n",
        "        if any(dom in lowered for dom in EXCLUDED_DOMAINS):\n",
        "            continue\n",
        "\n",
        "        cleaned.add(url.strip())\n",
        "    return cleaned\n",
        "\n",
        "def extract_urls(text: str) -> Set[str]:\n",
        "    return set(_URL_RE.findall(text or \"\"))\n",
        "\n",
        "\n",
        "GPT_URLS_STORE = \"gpt4_found_urls.json\"\n",
        "def load_urls_from_csv(csv_path: str = CSV_PATH,\n",
        "                       column: str = CSV_URLS_COLUMN) -> Set[str]:\n",
        "    \"\"\"\n",
        "    Reads the CSV at csv_path and extracts all URLs from the target column.\n",
        "    Returns a set of URLs (may be empty if file/column missing).\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df = pd.read_csv(csv_path)\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Could not read CSV at {csv_path}: {e}\")\n",
        "        return set()\n",
        "\n",
        "    if column not in df.columns:\n",
        "        print(f\"⚠️ Column not found: '{column}'. Available: {list(df.columns)}\")\n",
        "        return set()\n",
        "\n",
        "    urls: Set[str] = set()\n",
        "    for cell in df[column].dropna().astype(str):\n",
        "        urls |= extract_urls(cell)\n",
        "    return urls\n",
        "\n",
        "def load_gpt5_found_urls(path: str = GPT_URLS_STORE,\n",
        "                        csv_path: str = CSV_PATH,\n",
        "                        column: str = CSV_URLS_COLUMN) -> Set[str]:\n",
        "    \"\"\"\n",
        "    Loads URLs previously saved in JSON and merges with URLs extracted\n",
        "    from the Drive CSV column.\n",
        "    \"\"\"\n",
        "    merged: Set[str] = set()\n",
        "\n",
        "    # 1) URLs from CSV\n",
        "    csv_urls = load_urls_from_csv(csv_path, column)\n",
        "    if csv_urls:\n",
        "        merged |= csv_urls\n",
        "\n",
        "    # 2) URLs from JSON store (if present)\n",
        "    if os.path.exists(path):\n",
        "        try:\n",
        "            with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "                data = json.load(f)\n",
        "            if isinstance(data, list):\n",
        "                merged |= set(map(str, data))\n",
        "            else:\n",
        "                print(\"⚠️ JSON store not a list; ignoring its contents.\")\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Failed to load {path}: {e}\")\n",
        "\n",
        "    return merged\n",
        "\n",
        "\n",
        "def save_gpt5_found_urls(\n",
        "    urls: Set[str],\n",
        "    path: str = GPT_URLS_STORE,\n",
        "    also_merge_csv: bool = True,\n",
        "    csv_path: str = CSV_PATH,\n",
        "    column: str = CSV_URLS_COLUMN\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Saves the union of:\n",
        "      - provided `urls`\n",
        "      - existing JSON store\n",
        "      - (optionally) URLs parsed from the Drive CSV column\n",
        "\n",
        "    Then appends the full URLs (not just domains) to the global EXCLUDED_DOMAINS set.\n",
        "    \"\"\"\n",
        "    # 1️⃣ Merge URLs\n",
        "    existing = load_gpt5_found_urls(path, csv_path, column) if also_merge_csv else set()\n",
        "    #print(\"Existing URLs:\", existing)\n",
        "    valid_urls = _filter_real_urls(urls)\n",
        "    merged = sorted(existing | valid_urls)\n",
        "\n",
        "    # 2️⃣ Save merged URLs to file\n",
        "    try:\n",
        "        with open(path, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(merged, f, ensure_ascii=False, indent=2)\n",
        "        print(f\"✅ Saved {len(merged)} URLs to {path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Failed to save {path}: {e}\")\n",
        "        return\n",
        "\n",
        "    # 3️⃣ Append full URLs to EXCLUDED_DOMAINS\n",
        "    before_count = len(EXCLUDED_DOMAINS)\n",
        "    EXCLUDED_DOMAINS.update(existing)\n",
        "    after_count = len(EXCLUDED_DOMAINS)\n",
        "\n",
        "    print(f\"🔒 Updated EXCLUDED_DOMAINS: added {after_count - before_count} new URL(s).\")\n",
        "    print(f\"Total excluded entries: {after_count}\")\n",
        "    print(\"🧱 EXCLUDED_DOMAINS =\", EXCLUDED_DOMAINS)\n",
        "\n",
        "\n",
        "# 1) Pull URLs from CSV + existing JSON\n",
        "seed_urls = load_gpt5_found_urls()\n",
        "\n",
        "# 2) Add any new URLs (e.g., from a fresh GPT-4 output or another pass)\n",
        "new_urls = {\"https://example.com/a\", \"https://example.org/b\"}\n",
        "save_gpt5_found_urls(new_urls)   # merges CSV + existing JSON + new ones into the store\n",
        "\n",
        "# 3) Later: build your exclusion set from this store for SerpAPI searches\n",
        "gpt5_found_urls = load_gpt5_found_urls()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_Dxur6iZXgO",
        "outputId": "c1500316-7434-4398-e3b6-c2945f684cfb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 2 URLs to gpt4_found_urls.json\n",
            "🔒 Updated EXCLUDED_DOMAINS: added 2 new URL(s).\n",
            "Total excluded entries: 8\n",
            "🧱 EXCLUDED_DOMAINS = {'jetbrains.com.cn', 'https://stackoverflow.com/questions/3686808/spring-3-requestmapping-get-path-value:', 'https://www.baeldung.com/spring-pathvariable:', 'example.com', 'www.jetbrains.com', 'jetbrains.com', 'example.org', 'www.jetbrains.com.cn'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Iterable\n",
        "\n",
        "DEFAULT_EXCLUDES = {\n",
        "    \"jetbrains.com\",\n",
        "    \"www.jetbrains.com\",\n",
        "    \"jetbrains.com.cn\",\n",
        "    \"www.jetbrains.com.cn\",\n",
        "}\n",
        "\n",
        "# More automation number 5\n",
        "HOST_PRIORITY: Dict[str, int] = {\n",
        "    \"docs.jboss.org\": 100,             # Hibernate javadocs\n",
        "    \"spring.io\": 95,               # Hibernate website\n",
        "    \"jakarta.ee\": 80,                  # EE docs\n",
        "    \"jetbrains.com\": 70,               # Inspectopedia/IDEA docs\n",
        "    \"github.com\": 40,                  # Code often useful\n",
        "}\n",
        "\n",
        "def _fetch_text(url: str, timeout: int = 20) -> str:\n",
        "    resp = requests.get(url, timeout=timeout)\n",
        "    resp.raise_for_status()\n",
        "    soup = BeautifulSoup(resp.text, \"html.parser\")\n",
        "    for tag in soup([\"script\",\"style\",\"noscript\"]):\n",
        "        tag.decompose()\n",
        "    text = soup.get_text(separator=\"\\n\")\n",
        "    text = re.sub(r\"\\n\\s*\\n+\", \"\\n\\n\", text).strip()\n",
        "    return text\n",
        "\n",
        "def search_framework_find(framework: str, topic: str,\n",
        "                          jetbrains_intro: str, gpt4_expl: str,\n",
        "                          exclude_domains: Optional[Set[str]] = None,\n",
        "                          per_query: int = 10) -> List[dict]:\n",
        "    queries = build_candidate_queries(framework, topic, jetbrains_intro, gpt4_expl)\n",
        "\n",
        "    all_results: List[dict] = []\n",
        "    for q in queries:\n",
        "        batch = serpapi_search(q, exclude_domains=exclude_domains, num=per_query)\n",
        "        all_results.extend(batch)\n",
        "        time.sleep(0.2)  # be polite; SerpAPI handles rate limiting but avoid bursts\n",
        "\n",
        "    # Deduplicate by URL\n",
        "    dedup: Dict[str, dict] = {}\n",
        "    for r in all_results:\n",
        "        dedup[r[\"url\"]] = r\n",
        "    ranked = rerank(list(dedup.values()))\n",
        "    return ranked[:20]  # top-N\n",
        "\n",
        "def serpapi_search(query: str, exclude_domains: Optional[Set[str]] = None, num: int = 10) -> List[dict]:\n",
        "    \"\"\"\n",
        "    Returns a *list of result dicts* (we keep title/snippet for reranking).\n",
        "    \"\"\"\n",
        "    if not SERPAPI_API_KEY:\n",
        "        print(\"⚠️ No SerpAPI key provided.\")\n",
        "        return []\n",
        "\n",
        "    excludes = set(DEFAULT_EXCLUDES)\n",
        "    if exclude_domains:\n",
        "        excludes |= set(exclude_domains)\n",
        "\n",
        "    params = {\"engine\": \"google\", \"q\": query, \"api_key\": SERPAPI_API_KEY, \"num\": str(num)}\n",
        "    try:\n",
        "        r = requests.get(\"https://serpapi.com/search\", params=params, timeout=20)\n",
        "        r.raise_for_status()\n",
        "        data = r.json()\n",
        "        out = []\n",
        "        for item in data.get(\"organic_results\", []):\n",
        "            url = item.get(\"link\")\n",
        "            if not url:\n",
        "                continue\n",
        "            if is_excluded(url, excludes):\n",
        "                continue\n",
        "            out.append({\n",
        "                \"url\": url,\n",
        "                \"title\": item.get(\"title\", \"\"),\n",
        "                \"snippet\": item.get(\"snippet\", \"\"),\n",
        "                \"position\": item.get(\"position\"),\n",
        "            })\n",
        "        return out\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ SerpAPI request failed: {e}\")\n",
        "        return []\n",
        "\n",
        "def is_excluded(url: str, excluded_domains: Set[str]) -> bool:\n",
        "    \"\"\"Return True if the URL's host matches any excluded domain.\"\"\"\n",
        "    if not excluded_domains:\n",
        "        return False\n",
        "    host = _extract_domain(url)\n",
        "    return any(host == dom or host.endswith(f\".{dom}\") for dom in excluded_domains)\n",
        "\n",
        "def build_candidate_queries(framework: str, topic: str, jetbrains_intro: str, gpt5_expl: str) -> List[str]:\n",
        "    \"\"\"\n",
        "    Generate several strong Google queries with operators. We’ll try them all and then rerank results.\n",
        "    \"\"\"\n",
        "    ctx = normalize_space(\" \".join([framework or \"\", topic or \"\", jetbrains_intro or \"\", gpt5_expl or \"\"]))\n",
        "    terms = key_terms_from_text(ctx)\n",
        "    joined = \" \".join(terms) if terms else ctx\n",
        "\n",
        "    # Pay special attention to '@Find' literal\n",
        "    base = '\"@ConfigMapping\" annotation prefix attribute quarkus'\n",
        "\n",
        "    # More automation number 1.\n",
        "    candidates = [\n",
        "        # precision: official javadocs\n",
        "        f'site:docs.jboss.org {base}',\n",
        "        f'site:spring.io {base}',\n",
        "        # title/url hints\n",
        "        f'intitle:{base}',\n",
        "        f'inurl:spring intitle:PathVariable',\n",
        "        # allintext to bind concepts\n",
        "        f'allintext:PathVariable spring {joined}',\n",
        "        # combine with JetBrains if trying to verify Inspectopedia rule\n",
        "        f'site:jetbrains.com Inspectopedia \"PathVariable Spring MVC',\n",
        "        # fallback broad\n",
        "        f'{base} {joined}',\n",
        "    ]\n",
        "\n",
        "    # de-duplicate + keep short, valid strings\n",
        "    return uniq_preserve_order([normalize_space(c) for c in candidates if c.strip()])\n",
        "\n",
        "def _extract_domain(url: str) -> str:\n",
        "    try:\n",
        "        host = re.sub(r\"^https?://\", \"\", url, flags=re.IGNORECASE).split(\"/\")[0]\n",
        "        return host.lower()\n",
        "    except Exception:\n",
        "        return \"\"\n",
        "\n",
        "def normalize_space(s: str) -> str:\n",
        "    return re.sub(r\"\\s+\", \" \", s or \"\").strip()\n",
        "\n",
        "def key_terms_from_text(text: str, k: int = 8) -> List[str]:\n",
        "    \"\"\"\n",
        "    Cheap, dependency-free keyterm picker: keep tokens with @, camelCase, or java-ish/Dot terms; fallback to frequent words.\n",
        "    Replace with RAKE/TextRank if you like.\n",
        "    \"\"\"\n",
        "    if not text:\n",
        "        return []\n",
        "    toks = re.findall(r\"[@\\w\\.]+\", text)\n",
        "    # keep distinctive tokens\n",
        "    candidates = [t for t in toks if len(t) > 2]\n",
        "    # light heuristic boosts\n",
        "    def score(t: str) -> float:\n",
        "        s = 0.0\n",
        "        if t.startswith(\"@\"): s += 3\n",
        "        if \".\" in t: s += 1.5   # package/class names\n",
        "        if re.search(r\"[A-Z][a-z]+[A-Z]\", t): s += 1.0  # camelCase\n",
        "\n",
        "        # More automation number 2.\n",
        "        if t.lower() in {\"pathvariable\",\"requestmapping\",\"spring\",\"springmvc\",\"incorrect\",\"mismatch\"}:\n",
        "            s += 1.2\n",
        "        return s\n",
        "    ranked = sorted(candidates, key=lambda t: (score(t), len(t)), reverse=True)\n",
        "    out = uniq_preserve_order(ranked)[:k]\n",
        "    return out\n",
        "\n",
        "def uniq_preserve_order(seq: Iterable[str]) -> List[str]:\n",
        "    seen = set()\n",
        "    out = []\n",
        "    for s in seq:\n",
        "        if s not in seen:\n",
        "            seen.add(s)\n",
        "            out.append(s)\n",
        "    return out\n",
        "\n",
        "def rerank(results: List[dict]) -> List[dict]:\n",
        "    return sorted(results, key=feature_score, reverse=True)\n",
        "\n",
        "# More automation number 3\n",
        "def feature_score(result: dict) -> float:\n",
        "    \"\"\"\n",
        "    Score by: host priority, presence of '@Find' in title/snippet/url,\n",
        "    path hints like '/annotations/processing/Find'.\n",
        "    \"\"\"\n",
        "    url, title, snip = result.get(\"url\",\"\"), result.get(\"title\",\"\"), result.get(\"snippet\",\"\")\n",
        "    host = host_of(url)\n",
        "    score = HOST_PRIORITY.get(host, 0)\n",
        "\n",
        "    text = \" \".join([url, title, snip]).lower()\n",
        "    boosts = [\n",
        "        (r\"PathVariable\", 15),\n",
        "        (r\"\\bspring\\b\", 8),\n",
        "        (r\"\\vdeclaration(s)?\\b\", 5),\n",
        "        # (r\".io/smallrye-config/\", 12),\n",
        "        (r\"/spring(-)?mvc/\", 10),\n",
        "        # (r\"\\bprefix\\b\", 4),\n",
        "    ]\n",
        "    for pat, w in boosts:\n",
        "        if re.search(pat, text):\n",
        "            score += w\n",
        "\n",
        "    # slight boost for earlier rank\n",
        "    pos = result.get(\"position\")\n",
        "    if isinstance(pos, int):\n",
        "        score += max(0, 10 - pos)\n",
        "\n",
        "    return float(score)\n",
        "\n",
        "# -------------------------------\n",
        "# Helpers\n",
        "# -------------------------------\n",
        "def host_of(url: str) -> str:\n",
        "    try:\n",
        "        return urlparse(url).netloc.lower()\n",
        "    except Exception:\n",
        "        return \"\"\n",
        "\n",
        "def is_excluded(url: str, excluded_hosts: Set[str]) -> bool:\n",
        "    h = host_of(url)\n",
        "    return any(h == ex or h.endswith(f\".{ex}\") for ex in excluded_hosts)\n",
        "\n",
        "def uniq_preserve_order(seq: Iterable[str]) -> List[str]:\n",
        "    seen = set()\n",
        "    out = []\n",
        "    for s in seq:\n",
        "        if s not in seen:\n",
        "            seen.add(s)\n",
        "            out.append(s)\n",
        "    return out\n",
        "\n",
        "# -------------------------------\n",
        "# Query building\n",
        "# -------------------------------\n",
        "# def normalize_space(s: str) -> str:\n",
        "#     return re.sub(r\"\\s+\", \" \", s or \"\").strip()\n",
        "\n",
        "# def key_terms_from_text(text: str, k: int = 8) -> List[str]:\n",
        "#     \"\"\"\n",
        "#     Cheap, dependency-free keyterm picker: keep tokens with @, camelCase, or java-ish/Dot terms; fallback to frequent words.\n",
        "#     Replace with RAKE/TextRank if you like.\n",
        "#     \"\"\"\n",
        "#     if not text:\n",
        "#         return []\n",
        "#     toks = re.findall(r\"[@\\w\\.]+\", text)\n",
        "#     # keep distinctive tokens\n",
        "#     candidates = [t for t in toks if len(t) > 2]\n",
        "#     # light heuristic boosts\n",
        "#     def score(t: str) -> float:\n",
        "#         s = 0.0\n",
        "#         if t.startswith(\"@\"): s += 3\n",
        "#         if \".\" in t: s += 1.5   # package/class names\n",
        "#         if re.search(r\"[A-Z][a-z]+[A-Z]\", t): s += 1.0  # camelCase\n",
        "#         if t.lower() in {\"find\",\"finder\",\"annotation\",\"hibernate\",\"entity\",\"typedquery\",\"selectionquery\"}:\n",
        "#             s += 1.2\n",
        "#         return s\n",
        "#     ranked = sorted(candidates, key=lambda t: (score(t), len(t)), reverse=True)\n",
        "#     out = uniq_preserve_order(ranked)[:k]\n",
        "#     return out\n",
        "\n",
        "# def build_candidate_queries(framework: str, topic: str, jetbrains_intro: str, gpt5_expl: str) -> List[str]:\n",
        "#     \"\"\"\n",
        "#     Generate several strong Google queries with operators. We’ll try them all and then rerank results.\n",
        "#     \"\"\"\n",
        "#     ctx = normalize_space(\" \".join([framework or \"\", topic or \"\", jetbrains_intro or \"\", gpt5_expl or \"\"]))\n",
        "#     terms = key_terms_from_text(ctx)\n",
        "#     joined = \" \".join(terms) if terms else ctx\n",
        "\n",
        "#     # Pay special attention to '@Find' literal\n",
        "#     base = '\"@Find\" hibernate annotation'\n",
        "\n",
        "#     candidates = [\n",
        "#         # precision: official javadocs\n",
        "#         f'site:docs.jboss.org {base}',\n",
        "#         f'site:hibernate.org {base}',\n",
        "#         # title/url hints\n",
        "#         f'intitle:@Find hibernate annotation',\n",
        "#         f'inurl:hibernate intitle:@Find annotation',\n",
        "#         # allintext to bind concepts\n",
        "#         f'allintext:@Find hibernate entity finder {joined}',\n",
        "#         # combine with JetBrains if trying to verify Inspectopedia rule\n",
        "#         f'site:jetbrains.com Inspectopedia \"@Find\" hibernate',\n",
        "#         # fallback broad\n",
        "#         f'{base} {joined}',\n",
        "#     ]\n",
        "\n",
        "#     # de-duplicate + keep short, valid strings\n",
        "#     return uniq_preserve_order([normalize_space(c) for c in candidates if c.strip()])\n",
        "\n",
        "# -------------------------------\n",
        "# Lightweight reranking\n",
        "# # -------------------------------\n",
        "# def feature_score(result: dict) -> float:\n",
        "#     \"\"\"\n",
        "#     Score by: host priority, presence of '@Find' in title/snippet/url,\n",
        "#     path hints like '/annotations/processing/Find'.\n",
        "#     \"\"\"\n",
        "#     url, title, snip = result.get(\"url\",\"\"), result.get(\"title\",\"\"), result.get(\"snippet\",\"\")\n",
        "#     host = host_of(url)\n",
        "#     score = HOST_PRIORITY.get(host, 0)\n",
        "\n",
        "#     text = \" \".join([url, title, snip]).lower()\n",
        "\n",
        "#     # boosts = [\n",
        "#     #     (r\"@configmapping\", 15),\n",
        "#     #     (r\"\\bquarkus\\b\", 8),\n",
        "#     #     (r\"\\bannotation(s)?\\b\", 5),\n",
        "#     #     (r\".io/smallrye-config/\", 12),\n",
        "#     #     (r\"/smallrye/\", 10),\n",
        "#     #     (r\"\\bprefix\\b\", 4),\n",
        "#     # ]\n",
        "#     for pat, w in boosts:\n",
        "#         if re.search(pat, text):\n",
        "#             score += w\n",
        "\n",
        "#     # slight boost for earlier rank\n",
        "#     pos = result.get(\"position\")\n",
        "#     if isinstance(pos, int):\n",
        "#         score += max(0, 10 - pos)\n",
        "\n",
        "#     return float(score)\n",
        "\n",
        "def rerank(results: List[dict]) -> List[dict]:\n",
        "    return sorted(results, key=feature_score, reverse=True)\n",
        "\n",
        "# -------------------------------\n",
        "# Orchestrator\n",
        "# -------------------------------\n",
        "def search__find(framework: str, topic: str,\n",
        "                          jetbrains_intro: str, gpt4_expl: str,\n",
        "                          exclude_domains: Optional[Set[str]] = None,\n",
        "                          per_query: int = 10) -> List[dict]:\n",
        "    queries = build_candidate_queries(framework, topic, jetbrains_intro, gpt4_expl)\n",
        "\n",
        "    all_results: List[dict] = []\n",
        "    for q in queries:\n",
        "        batch = serpapi_search(q, exclude_domains=exclude_domains, num=per_query)\n",
        "        all_results.extend(batch)\n",
        "        time.sleep(0.2)  # be polite; SerpAPI handles rate limiting but avoid bursts\n",
        "\n",
        "    # Deduplicate by URL\n",
        "    dedup: Dict[str, dict] = {}\n",
        "    for r in all_results:\n",
        "        dedup[r[\"url\"]] = r\n",
        "    ranked = rerank(list(dedup.values()))\n",
        "    return ranked[:20]  # top-N\n"
      ],
      "metadata": {
        "id": "casy8sRwNbMl"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Prereqs --------------------------------------------------------------\n",
        "# - serpapi_search() helper OR inline SerpAPI call\n",
        "# - SOURCE / FRAMEWORK / TOPIC and your intro loader\n",
        "# I wanted to also try to let the model (GPT-4) decide the query and inject the search results as a tool call.\n",
        "# --- THESE TWO APPROACHES WOREKD !!! --------------------------------------------------------------\n",
        "\n",
        "from openai import OpenAI\n",
        "import json, re\n",
        "client = OpenAI()\n",
        "\n",
        "# A thin wrapper that also enforces your exclusions.\n",
        "def serpapi_search_excluding(q: str, exclude: set, num: int = 10) -> list[str]:\n",
        "    # merge per-call excludes with your defaults\n",
        "    merged_excludes = set(exclude) | {\n",
        "        \"jetbrains.com\",\"www.jetbrains.com\",\n",
        "        \"jetbrains.com.cn\",\"www.jetbrains.com.cn\",\n",
        "    }\n",
        "    # call your existing helper\n",
        "    urls = serpapi_search(q, merged_excludes)\n",
        "    return urls[:num]\n",
        "\n",
        "# --- 1) Define the tool schema the model can call ---------------------------\n",
        "tools = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"serpapi_search_tool\",\n",
        "            \"description\": \"Run a Google search via SerpAPI and return third-party URLs (JetBrains excluded).\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"q\": {\"type\": \"string\", \"description\": \"The exact Google query to run.\"},\n",
        "                    \"max\": {\"type\": \"integer\", \"description\": \"Max URLs to return (<=10).\", \"default\": 5},\n",
        "                    \"exclude\": {\n",
        "                        \"type\": \"array\",\n",
        "                        \"items\": {\"type\": \"string\"},\n",
        "                        \"description\": \"Full URLs or domains to exclude\"\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"q\"]\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "]\n",
        "\n",
        "# --- 2) Prepare the conversation -------------------------------------------\n",
        "def source_intro_before_locating(url: str) -> str:\n",
        "    txt = _fetch_text(url)\n",
        "    m = re.search(r\"Locating\\s+this\\s+inspection\", txt, flags=re.IGNORECASE)\n",
        "    return txt[:m.start()].strip() if m else txt.strip()\n",
        "\n",
        "def build_context(rule: dict | str) -> str:\n",
        "    gpt4_desc = load_gpt4_rule_description()  # your saved description (may be \"\")\n",
        "    rule_text = rule.get(\"rule\") or rule.get(\"name\") or rule.get(\"description\") if isinstance(rule, dict) else str(rule)\n",
        "    intro = source_intro_before_locating(SOURCE)\n",
        "    context = re.sub(r\"\\s+\", \" \", f\"{FRAMEWORK} {intro} {gpt4_desc} {rule_text} {TOPIC}\").strip()\n",
        "    return context\n",
        "\n",
        "system_msg = {\n",
        "    \"role\": \"system\",\n",
        "    \"content\": (\n",
        "        \"You are an analyst. Decide the BEST Google query for SerpAPI to find a NEW third-party page that \"\n",
        "        \"specifically addresses the rule context. Prefer queries that are precise (use allintext/intitle if helpful). \"\n",
        "        \"Do NOT return JetBrains links. When you need to search, CALL the serpapi_search_tool exactly once with your query.\"\n",
        "    )\n",
        "}\n",
        "\n",
        "def ask_model_to_search(rule, excluded:set):\n",
        "    user_msg = {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": (\n",
        "            \"Context for the rule:\\n\"\n",
        "            f\"{build_context(rule)}\\n\\n\"\n",
        "            \"Goal: Find ONE new relevant third-party URL that discusses this rule/topic. \"\n",
        "            \"Return the single best URL and a one-sentence why-it’s-relevant.\"\n",
        "        )\n",
        "    }\n",
        "\n",
        "    # --- 3) First turn: model decides the query and issues a tool call ------\n",
        "    first = client.chat.completions.create(\n",
        "        model=\"gpt-5\",\n",
        "        messages=[system_msg, user_msg],\n",
        "        tools=tools,\n",
        "        tool_choice=\"auto\"\n",
        "    )\n",
        "\n",
        "    msg = first.choices[0].message\n",
        "    tool_calls = getattr(msg, \"tool_calls\", None)\n",
        "\n",
        "    if not tool_calls:\n",
        "        # Model chose not to search; just return its content (unlikely by design)\n",
        "        return {\"url\": \"\", \"rationale\": msg.content or \"\"}\n",
        "\n",
        "    # Expect exactly one tool call\n",
        "    tc = tool_calls[0]\n",
        "    if tc.function.name != \"serpapi_search_tool\":\n",
        "        return {\"url\": \"\", \"rationale\": \"Model called unexpected tool.\"}\n",
        "\n",
        "    # Parse tool args\n",
        "    args = json.loads(tc.function.arguments or \"{}\")\n",
        "    q    = args.get(\"q\", \"\")\n",
        "    k    = int(args.get(\"max\", 5))\n",
        "    ex   = set(args.get(\"exclude\") or set()) | excluded\n",
        "\n",
        "    # Run the tool (SerpAPI) ourselves\n",
        "    urls = serpapi_search_excluding(q, ex, num=min(k, 10))\n",
        "\n",
        "    # --- 4) Send tool results back to the model -----------------------------\n",
        "    tool_result_msg = {\n",
        "        \"role\": \"tool\",\n",
        "        \"tool_call_id\": tc.id,\n",
        "        \"name\": \"serpapi_search_tool\",\n",
        "        \"content\": json.dumps({\"query\": q, \"results\": urls}, ensure_ascii=False)\n",
        "    }\n",
        "\n",
        "    final = client.chat.completions.create(\n",
        "        model=\"gpt-5\",\n",
        "        messages=[system_msg, user_msg, msg, tool_result_msg]\n",
        "    )\n",
        "\n",
        "    out = final.choices[0].message.content.strip() if final.choices else \"\"\n",
        "    # Optional: parse the model's final answer to extract the best URL\n",
        "    # Expect format like: \"Best URL: https://example.com\\nWhy: ...\"\n",
        "    m = re.search(r\"(https?://\\S+)\", out)\n",
        "    best_url = m.group(1) if m else (urls[0] if urls else \"\")\n",
        "    return {\"url\": best_url, \"rationale\": out}\n",
        "\n",
        "# --- 5) Usage ---------------------------------------------------------------\n",
        "# Build the live exclusion set (exact URLs + domains)\n",
        "gpt5_found_urls = load_gpt5_found_urls()  # your persisted set\n",
        "current_exclusions = set(EXCLUDED_DOMAINS) | set(gpt5_found_urls)\n",
        "\n",
        "# More automation number 4.\n",
        "result = ask_model_to_search(rule={\"rule\":{TOPIC}}, excluded=current_exclusions)\n",
        "print(\"Chosen URL:\", result[\"url\"])\n",
        "print(\"Model rationale:\\n\", result[\"rationale\"])\n",
        "\n",
        "# Optionally persist and exclude for future rounds\n",
        "if result[\"url\"]:\n",
        "    save_gpt5_found_urls({result[\"url\"]})\n",
        "\n",
        "\n",
        "framework = FRAMEWORK            # e.g., \"Hibernate ORM 6.x\"\n",
        "topic = TOPIC                    # e.g., \"Finder methods with @Find\"\n",
        "jetbrains_intro = load_new_rule_explanation(GPT4_RULE_DESCRIPTION_PATH)   # scraped from JetBrains web page\n",
        "\n",
        "gpt5_expl = load_gpt4_rule_description(newRULE_EXPLANATIONS_PATH)              # your own summary, optional\n",
        "\n",
        "top = search_framework_find(framework, topic, jetbrains_intro, gpt5_expl)\n",
        "for r in top[:5]:\n",
        "    print(r[\"url\"], \"—\", r[\"title\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqUgLFiwNOks",
        "outputId": "80b4500d-ab70-4a31-cba5-aa4ff05366fb"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chosen URL: https://rameshfadatare.medium.com/spring-boot-pathvariable-annotation-explained-extract-values-from-url-ab2d1cf0f961\n",
            "Model rationale:\n",
            " https://rameshfadatare.medium.com/spring-boot-pathvariable-annotation-explained-extract-values-from-url-ab2d1cf0f961\n",
            "\n",
            "This tutorial explains that method parameter names must match the URI template variables (or be explicitly named via @PathVariable(\"...\")), directly addressing the mismatch issue the rule detects.\n",
            "✅ Saved 3 URLs to gpt4_found_urls.json\n",
            "🔒 Updated EXCLUDED_DOMAINS: added 0 new URL(s).\n",
            "Total excluded entries: 8\n",
            "🧱 EXCLUDED_DOMAINS = {'jetbrains.com.cn', 'https://www.baeldung.com/spring-pathvariable:', 'https://stackoverflow.com/questions/3686808/spring-3-requestmapping-get-path-value:', 'www.jetbrains.com', 'example.org', 'www.jetbrains.com.cn', 'example.com', 'jetbrains.com'}\n",
            "⚠️ No saved GPT-4 rule description found.\n",
            "https://mkyong.com/spring-mvc/spring-pathvariable-annotation/ — Spring @PathVariable Annotation\n",
            "https://howtodoinjava.com/spring-mvc/spring-pathvariable-and-requestparam/ — Spring @PathVariable and @RequestParam (+ Examples)\n",
            "https://www.baeldung.com/spring-pathvariable — Spring @PathVariable Annotation\n",
            "https://medium.com/@AlexanderObregon/the-mechanics-of-request-mapping-in-spring-boot-92d1065cc0ad — The Mechanics of Request Mapping in Spring Boot\n",
            "https://www.jetbrains.com/help/inspectopedia/Spring-Spring-MVC.html — Spring MVC | Inspectopedia Documentation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Rule Validation Utilities (Using SerpAPI) ---\n",
        "# --- Naive apporoch of combining all contexts in text form\n",
        "import html\n",
        "\n",
        "def _extract_domain(url: str) -> str:\n",
        "    try:\n",
        "        host = re.sub(r\"^https?://\", \"\", url, flags=re.IGNORECASE).split(\"/\")[0]\n",
        "        return host.lower()\n",
        "    except Exception:\n",
        "        return \"\"\n",
        "\n",
        "def is_excluded(url: str, excluded_domains: Set[str]) -> bool:\n",
        "    \"\"\"Return True if the URL's host matches any excluded domain.\"\"\"\n",
        "    if not excluded_domains:\n",
        "        return False\n",
        "    host = _extract_domain(url)\n",
        "    return any(host == dom or host.endswith(f\".{dom}\") for dom in excluded_domains)\n",
        "\n",
        "def serpapi_search(query: str, exclude_domains: Optional[Set[str]] = None, num: int = 10) -> List[str]:\n",
        "    \"\"\"\n",
        "    Searches Google via SerpAPI and returns URLs that are *not* excluded.\n",
        "    Exclusions = DEFAULT_EXCLUDES + domains derived from GPT-found URLs (by host) + caller-provided excludes.\n",
        "    \"\"\"\n",
        "    if not SERPAPI_API_KEY:\n",
        "        print(\"⚠️ No SerpAPI key provided.\")\n",
        "        return []\n",
        "\n",
        "    try:\n",
        "        params = {\"engine\": \"google\", \"q\": query, \"api_key\": SERPAPI_API_KEY, \"num\": str(num)}\n",
        "\n",
        "        r = requests.get(\"https://serpapi.com/search\", params=params, timeout=20)\n",
        "        r.raise_for_status()\n",
        "        data = r.json()\n",
        "        out = []\n",
        "        for item in data.get(\"organic_results\", []):\n",
        "           print(item)\n",
        "           url = item.get(\"link\")\n",
        "           if url and not is_excluded(url, EXCLUDED_DOMAINS):\n",
        "                 #print(out)\n",
        "                 out.append(url)\n",
        "        return out\n",
        "    except Exception:\n",
        "        print(\"⚠️ SerpAPI request failed.\")\n",
        "        return []\n",
        "\n",
        "def build_query_from_rule(rule: dict | str) -> str:\n",
        "    \"\"\"\n",
        "    Build a SerpAPI query using:\n",
        "      - The SOURCE intro (before 'Locating this inspection')\n",
        "      - The saved GPT-5 rule description (if available)\n",
        "      - FRAMEWORK and TOPIC context\n",
        "    Adds Google's 'allintext:' operator to focus on pages that\n",
        "    contain all contextual words in the page body.\n",
        "    \"\"\"\n",
        "    # 1️⃣ Load saved GPT-4 rule description (if any)\n",
        "    gpt5_rule_description = load_gpt4_rule_description()\n",
        "\n",
        "    # 2️⃣ Get Inspectopedia intro (before 'Locating this inspection')\n",
        "    intro = source_intro_before_locating(SOURCE)\n",
        "\n",
        "    # 3️⃣ Get explanation of the new generated rule\n",
        "    newR = load_gpt4_rule_description(newRULE_EXPLANATIONS_PATH)\n",
        "\n",
        "\n",
        "    # 4️⃣  Combine all contexts\n",
        "    # More context could be combined or RAG could be used\n",
        "    combined_context = f\"{FRAMEWORK}, {newR} ,{TOPIC}\"\n",
        "\n",
        "    # 5️⃣ Clean and normalize whitespace\n",
        "    # tokens = [t for t in re.split(r\"[^\\w@]+\", f\"{combined_text}\") if t]\n",
        "    # key = \" \".join(tokens[:10]) if tokens else FRAMEWORK\n",
        "    combined_context = re.sub(r\"\\s+\", \" \", combined_context).strip()\n",
        "    print(\"Combined context:\", combined_context)\n",
        "\n",
        "    # Instead of simplying combining the three blobs, there must be a way we can optimize the query so that\n",
        "    # https://docs.jboss.org/hibernate/orm/6.5/javadocs/org/hibernate/annotations/processing/Find.html could be located\n",
        "    # https://serpapi.com/blog/ultimate-guide-to-google-search-operators-2023-guide/\n",
        "    # with allinstext: operator, it finds JetBrains web page for \"@find\"\n",
        "    # return f\"allintext:({combined_context})\"\n",
        "    return f\"{\"@configmapping\", {combined_context}}\"\n",
        "\n",
        "def validate_rule_via_serpapi(rule_text: str,\n",
        "                              excluded_domains: Optional[Set[str]] = None,\n",
        "                              max_urls: int = 3) -> Dict[str, object]:\n",
        "    \"\"\"\n",
        "    Uses SerpAPI with an allintext-based query for higher relevancy.\n",
        "    Returns up to `max_urls` URLs excluding JetBrains and other specified domains.\n",
        "    \"\"\"\n",
        "    q = build_query_from_rule(rule_text)\n",
        "    print(f\"🔍 SerpAPI query:\\n{q}\\n\")\n",
        "\n",
        "    urls = serpapi_search(q, excluded_domains or set())\n",
        "\n",
        "    if not urls:\n",
        "        print(\"⚠️ No URLs found — query may be too specific or context too long. Try shortening the input.\")\n",
        "    else:\n",
        "        print(f\"✅ Found {len(urls)} URLs:\")\n",
        "        for u in urls:\n",
        "            print(\" •\", u)\n",
        "\n",
        "    return {\"query\": q, \"urls\": urls[:max_urls]}\n",
        "\n",
        "def validate_rule_via_serpapi(rule_text: str,\n",
        "                              exclude_domains: Optional[Set[str]] = None,\n",
        "                              max_urls: int = 1) -> Dict[str, object]:\n",
        "    q = build_query_from_rule(rule_text)\n",
        "    urls = serpapi_search(q, EXCLUDED_DOMAINS or set())\n",
        "    return {\"query\": q, \"urls\": urls[:max_urls]}\n",
        "\n",
        "query = build_query_from_rule({\"content\": CONTENT})\n",
        "#serpapi_third_party_urls = serpapi_search(query)\n",
        "r = validate_rule_via_serpapi(query)\n",
        "urls_only = r[\"urls\"]\n",
        "print(urls_only)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLMbveJ2YIt3",
        "outputId": "54029b14-9220-4f76-ff1e-c22fdd20248f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined context: Spring MVC, The rule 'pathVariable-mismatch' checks for mismatches between @PathVariable parameters declared in the method signature and those used in the URL path. It iterates over all classes and their methods. If a method has the @RequestMapping annotation, it retrieves the URL path. Then, for each field in the method, if it has the @PathVariable annotation, it checks if the variable name is present in the URL path. If not, it raises an error message. Similarly, it checks for each variable in the URL path if it is declared in the method signature. If not, it raises an error message. ,Mismatch in @PathVariable declarations and usages\n",
            "Combined context: Spring MVC, The rule 'pathVariable-mismatch' checks for mismatches between @PathVariable parameters declared in the method signature and those used in the URL path. It iterates over all classes and their methods. If a method has the @RequestMapping annotation, it retrieves the URL path. Then, for each field in the method, if it has the @PathVariable annotation, it checks if the variable name is present in the URL path. If not, it raises an error message. Similarly, it checks for each variable in the URL path if it is declared in the method signature. If not, it raises an error message. ,Mismatch in @PathVariable declarations and usages\n",
            "{'position': 1, 'title': 'Mismatch in @PathVariable resolving - spring mvc', 'link': 'https://stackoverflow.com/questions/31403203/mismatch-in-pathvariable-resolving', 'redirect_link': 'https://www.google.com/url?sa=t&source=web&rct=j&opi=89978449&url=https://stackoverflow.com/questions/31403203/mismatch-in-pathvariable-resolving&ved=2ahUKEwj2ydOlneGQAxXvOjQIHfuiLB0QFnoECCMQAQ', 'displayed_link': '1 answer · 10 years ago', 'favicon': 'https://serpapi.com/searches/690e8582a3ce84697010112b/images/9c0b9531cc6ded4fd3c051ea65eb8eea4aab4a498505ec73d48da1e7fb734f06.png', 'snippet': 'Let\\'s suppose to have this method signature: @RequestMapping(value = \"/verifyusers/{site}/{users}\", method = RequestMethod.GET) @ResponseBody ...', 'snippet_highlighted_words': ['have', 'method signature', 'RequestMapping', 'method'], 'sitelinks': {'list': [{'title': 'java - Spring Web MVC: Use same request mapping for ...', 'link': 'https://stackoverflow.com/questions/2745471/spring-web-mvc-use-same-request-mapping-for-request-parameter-and-path-variable', 'answer_count': 3, 'date': 'Apr 30, 2010'}, {'title': 'How to properly manage PathVariables with spring', 'link': 'https://stackoverflow.com/questions/34703568/how-to-properly-manage-pathvariables-with-spring', 'answer_count': 5, 'date': 'Jan 10, 2016'}]}, 'source': 'Stack Overflow'}\n",
            "{'position': 2, 'title': 'Spring @PathVariable Annotation', 'link': 'https://www.baeldung.com/spring-pathvariable', 'redirect_link': 'https://www.google.com/url?sa=t&source=web&rct=j&opi=89978449&url=https://www.baeldung.com/spring-pathvariable&ved=2ahUKEwj2ydOlneGQAxXvOjQIHfuiLB0QFnoECBoQAQ', 'displayed_link': 'https://www.baeldung.com › ... › Spring MVC', 'favicon': 'https://serpapi.com/searches/690e8582a3ce84697010112b/images/9c0b9531cc6ded4fd3c051ea65eb8eea72897ec61523a528aa2f35d8c129486d.png', 'date': 'Jan 8, 2024', 'snippet': \"In this quick tutorial, we'll explore Spring's @PathVariable annotation. Simply put, the @PathVariable annotation can be used to handle ...\", 'snippet_highlighted_words': [\"Spring's\", 'PathVariable annotation', 'PathVariable annotation', 'used'], 'missing': ['@configmapping', 'rule', 'mismatch', 'declared', 'signature', '@requestmapping'], 'source': 'Baeldung'}\n",
            "{'position': 3, 'title': 'URL Matching with PathPattern in Spring MVC', 'link': 'https://spring.io/blog/2020/06/30/url-matching-with-pathpattern-in-spring-mvc', 'redirect_link': 'https://www.google.com/url?sa=t&source=web&rct=j&opi=89978449&url=https://spring.io/blog/2020/06/30/url-matching-with-pathpattern-in-spring-mvc&ved=2ahUKEwj2ydOlneGQAxXvOjQIHfuiLB0QFnoECE4QAQ', 'displayed_link': 'https://spring.io › blog › 2020/06/30 › url-matching-wi...', 'favicon': 'https://serpapi.com/searches/690e8582a3ce84697010112b/images/9c0b9531cc6ded4fd3c051ea65eb8eea4a557771227f10e8d993fb264a00fd4f.png', 'date': 'Jun 30, 2020', 'snippet': 'In Spring applications AntPathMatcher is used to identify classpath, file system, remote, and other resources in Spring configuration. It has ...', 'snippet_highlighted_words': ['Spring', 'is used', 'Spring', 'has'], 'source': 'spring.io'}\n",
            "{'position': 4, 'title': 'check the parameters matching for the mapping methods ...', 'link': 'https://youtrack.jetbrains.com/issue/IDEA-252816/Spring-MVC-check-the-parameters-matching-for-the-mapping-methods-inherited-from-interface-in-case-of-path-variables-presence', 'redirect_link': 'https://www.google.com/url?sa=t&source=web&rct=j&opi=89978449&url=https://youtrack.jetbrains.com/issue/IDEA-252816/Spring-MVC-check-the-parameters-matching-for-the-mapping-methods-inherited-from-interface-in-case-of-path-variables-presence&ved=2ahUKEwj2ydOlneGQAxXvOjQIHfuiLB0QFnoECEcQAQ', 'displayed_link': 'https://youtrack.jetbrains.com › issue › IDEA-252816', 'favicon': 'https://serpapi.com/searches/690e8582a3ce84697010112b/images/9c0b9531cc6ded4fd3c051ea65eb8eea5200e2525f1786800865b8d9d1d14d86.png', 'snippet': 'Spring MVC: check the parameters matching for the mapping methods inherited from interface in case of path variables presence.', 'snippet_highlighted_words': ['Spring MVC', 'check', 'parameters', 'methods', 'from', 'of path'], 'source': 'JetBrains'}\n",
            "{'position': 5, 'title': \"Problem with Spring's @PathVariable across builds\", 'link': 'https://sgerogia.github.io/Problem-with-Springs-PathVariable-across-Builds/', 'redirect_link': 'https://www.google.com/url?sa=t&source=web&rct=j&opi=89978449&url=https://sgerogia.github.io/Problem-with-Springs-PathVariable-across-Builds/&ved=2ahUKEwj2ydOlneGQAxXvOjQIHfuiLB0QFnoECEgQAQ', 'displayed_link': 'https://sgerogia.github.io › Problem-with-Springs-Path...', 'favicon': 'https://serpapi.com/searches/690e8582a3ce84697010112b/images/9c0b9531cc6ded4fd3c051ea65eb8eeaa619190bb0ab4f55124d9d8de5b37337.jpeg', 'date': 'Sep 11, 2015', 'snippet': \"Debugging an issue with Spring's PathVariable annotations.\", 'snippet_highlighted_words': [\"Spring's PathVariable annotations\"], 'source': 'GitHub'}\n",
            "{'position': 6, 'title': 'A Comprehensive Guide to @PathVariable and ...', 'link': 'https://medium.com/@Mohd_Aamir_17/a-comprehensive-guide-to-pathvariable-and-requestparam-in-spring-boot-when-to-use-each-5dec54b314b5', 'redirect_link': 'https://www.google.com/url?sa=t&source=web&rct=j&opi=89978449&url=https://medium.com/%40Mohd_Aamir_17/a-comprehensive-guide-to-pathvariable-and-requestparam-in-spring-boot-when-to-use-each-5dec54b314b5&ved=2ahUKEwj2ydOlneGQAxXvOjQIHfuiLB0QFnoECE8QAQ', 'displayed_link': '10+ likes · 12 months ago', 'favicon': 'https://serpapi.com/searches/690e8582a3ce84697010112b/images/9c0b9531cc6ded4fd3c051ea65eb8eea74dfa8932fe292675002fbbb5e0f07c1.png', 'snippet': 'Definition: @PathVariable binds a method parameter to a URI template variable. Use Case: Use @PathVariable when the value forms part of the URL ...', 'snippet_highlighted_words': ['PathVariable', 'method parameter', 'Use', 'Use', 'PathVariable', 'of', 'URL'], 'missing': ['@configmapping', 'MVC,', 'rule', 'mismatch', 'checks', 'declared', 'signature', 'iterates', 'classes', '@requestmapping'], 'source': 'Medium · Mohd Aamir'}\n",
            "{'position': 7, 'title': 'MissingPathVariableException not thrown when the path ...', 'link': 'https://github.com/spring-projects/spring-boot/issues/25846', 'redirect_link': 'https://www.google.com/url?sa=t&source=web&rct=j&opi=89978449&url=https://github.com/spring-projects/spring-boot/issues/25846&ved=2ahUKEwj2ydOlneGQAxXvOjQIHfuiLB0QFnoECEsQAQ', 'displayed_link': 'https://github.com › spring-projects › spring-boot › issues', 'favicon': 'https://serpapi.com/searches/690e8582a3ce84697010112b/images/9c0b9531cc6ded4fd3c051ea65eb8eea96763deebfabcfc2eea86fce07e47748.png', 'date': 'Mar 31, 2021', 'snippet': 'Typically that means the URI template does not match the path variable name declared on the method parameter. Turning off the firewall rule with ...', 'snippet_highlighted_words': ['that', 'does not match', 'path variable', 'declared on', 'method parameter', 'rule'], 'missing': ['@configmapping', 'checks', 'mismatches', 'iterates', 'methods.', 'retrieves'], 'source': 'GitHub'}\n",
            "{'position': 8, 'title': 'Spring MVC @RequestMapping Annotation Example with ...', 'link': 'https://www.digitalocean.com/community/tutorials/spring-requestmapping-requestparam-pathvariable-example', 'redirect_link': 'https://www.google.com/url?sa=t&source=web&rct=j&opi=89978449&url=https://www.digitalocean.com/community/tutorials/spring-requestmapping-requestparam-pathvariable-example&ved=2ahUKEwj2ydOlneGQAxXvOjQIHfuiLB0QFnoECE0QAQ', 'displayed_link': 'https://www.digitalocean.com › community › tutorials', 'favicon': 'https://serpapi.com/searches/690e8582a3ce84697010112b/images/9c0b9531cc6ded4fd3c051ea65eb8eea503de3c026c91bc0a88f88273578006c.png', 'date': 'Aug 3, 2022', 'snippet': 'RequestMapping annotation is used to map web requests onto specific handler classes and/or handler methods.', 'snippet_highlighted_words': ['RequestMapping annotation is used', 'classes', 'methods'], 'missing': ['@configmapping', 'rule', 'mismatch', 'mismatches', 'declared', 'signature', 'iterates'], 'source': 'DigitalOcean'}\n",
            "{'position': 9, 'title': 'Spring Boot - @PathVariable and @RequestParam ...', 'link': 'https://www.geeksforgeeks.org/springboot/spring-boot-pathvariable-and-requestparam-annotations/', 'redirect_link': 'https://www.google.com/url?sa=t&source=web&rct=j&opi=89978449&url=https://www.geeksforgeeks.org/springboot/spring-boot-pathvariable-and-requestparam-annotations/&ved=2ahUKEwj2ydOlneGQAxXvOjQIHfuiLB0QFnoECEoQAQ', 'displayed_link': 'https://www.geeksforgeeks.org › springboot › spring-b...', 'favicon': 'https://serpapi.com/searches/690e8582a3ce84697010112b/images/9c0b9531cc6ded4fd3c051ea65eb8eea8b1eeaa3b34179d44485cbe1f1caa40c.png', 'date': 'Jul 23, 2025', 'snippet': 'The @PathVariable annotation is used to extract data from the URL path. It allows you to define placeholders in your request mapping URL and bind those ...', 'snippet_highlighted_words': ['PathVariable annotation is used', 'from', 'URL path', 'your request mapping URL'], 'missing': ['@configmapping', 'rule', 'mismatch', 'checks', 'mismatches', 'iterates', 'methods.'], 'source': 'GeeksforGeeks'}\n",
            "{'position': 10, 'title': 'Spring @PathVariable and @RequestParam (+ Examples)', 'link': 'https://howtodoinjava.com/spring-mvc/spring-pathvariable-and-requestparam/', 'redirect_link': 'https://www.google.com/url?sa=t&source=web&rct=j&opi=89978449&url=https://howtodoinjava.com/spring-mvc/spring-pathvariable-and-requestparam/&ved=2ahUKEwj2ydOlneGQAxXvOjQIHfuiLB0QFnoECEkQAQ', 'displayed_link': 'https://howtodoinjava.com › Spring MVC', 'favicon': 'https://serpapi.com/searches/690e8582a3ce84697010112b/images/9c0b9531cc6ded4fd3c051ea65eb8eeaa8ab8a2b12530ec9c1de386a5384ad66.png', 'date': 'Jul 25, 2023', 'snippet': 'This article explores the difference between @PathVariable and @RequestParam annotations in Spring, as well as compares these to their equivalents.', 'snippet_highlighted_words': ['between', 'PathVariable', 'annotations', 'Spring', 'these', 'their'], 'source': 'HowToDoInJava'}\n",
            "['https://stackoverflow.com/questions/31403203/mismatch-in-pathvariable-resolving']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Appending SerpAPI-found-URL into the CSV file\n",
        "CSV_PATH = \"/content/original_rsl_generated_rules.csv\"\n",
        "NEW_URLS_COLUMN = \"SerpAPI-found URLs\"\n",
        "\n",
        "def append_serpapi_urls_to_csv(serpapi_output: dict, csv_path: str = CSV_PATH, column: str = NEW_URLS_COLUMN):\n",
        "    \"\"\"\n",
        "    Append the SerpAPI-found URLs into the existing CSV file.\n",
        "    - Creates the column if it doesn't exist.\n",
        "    - Keeps old rows intact.\n",
        "    - Avoids duplicates inside the column for the same row.\n",
        "    \"\"\"\n",
        "\n",
        "    # Load the CSV from Google Drive\n",
        "    if not os.path.exists(csv_path):\n",
        "        raise FileNotFoundError(f\"❌ CSV not found at {csv_path}. Please verify the path.\")\n",
        "\n",
        "    df = pd.read_csv(csv_path)\n",
        "\n",
        "    # Ensure the new column exists\n",
        "    if column not in df.columns:\n",
        "        df[column] = \"\"\n",
        "\n",
        "    # Extract URLs from SerpAPI result dictionary\n",
        "    new_urls = urls_only\n",
        "    if not new_urls:\n",
        "        print(\"⚠️ No URLs found in SerpAPI output — nothing to append.\")\n",
        "        return df\n",
        "\n",
        "    # Convert to string format (e.g., \"url1; url2; url3\")\n",
        "    new_urls_str = \"; \".join(new_urls)\n",
        "\n",
        "    # Append the URLs to the last (most recent) row, or create a new row\n",
        "    if len(df) > 0:\n",
        "        last_idx = df.index[-1]\n",
        "        existing = str(df.at[last_idx, column])\n",
        "        if existing and isinstance(existing, str):\n",
        "            # Avoid duplicates in same cell\n",
        "            combined = set(existing.split(\"; \")) | set(new_urls)\n",
        "            df.at[last_idx, column] = \"; \".join(sorted(combined))\n",
        "        else:\n",
        "            df.at[last_idx, column] = new_urls_str\n",
        "    else:\n",
        "        # If the file is empty, start fresh\n",
        "        df = pd.DataFrame([{column: new_urls_str}])\n",
        "\n",
        "    # Save back to Drive\n",
        "    df.to_csv(csv_path, index=False)\n",
        "    print(f\"✅ Appended {len(new_urls)} SerpAPI URL(s) to {csv_path}\")\n",
        "    return df\n",
        "\n",
        "updated_df = append_serpapi_urls_to_csv(r)\n",
        "\n",
        "# Preview the last row\n",
        "print(updated_df.tail(1))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZ2TtQcKJuBo",
        "outputId": "e3a385ab-c548-42ff-f8a2-f3eec74f24fd"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Appended 1 SerpAPI URL(s) to /content/original_rsl_generated_rules.csv\n",
            "    framework                    source URL (JetBrains web page)  \\\n",
            "0  Spring MVC  https://www.jetbrains.com/help/idea/spring-sup...   \n",
            "\n",
            "  brief_description of the content in the source URL  \\\n",
            "0  The JetBrains web page provides a comprehensiv...   \n",
            "\n",
            "                                GPT-4 generated_rule  \\\n",
            "0  Rule pathVariable-mismatch {\\n  for (class c i...   \n",
            "\n",
            "               generated_rule_explanation from GPT-4  \\\n",
            "0  The rule 'pathVariable-mismatch' checks for mi...   \n",
            "\n",
            "   new_built-in_functions_explanation if any  \\\n",
            "0                                        NaN   \n",
            "\n",
            "                                PRE_model_validation  \\\n",
            "0  The generated rule seems to be valid as it fol...   \n",
            "\n",
            "  3rd-party most relevant URLs and summary for each URL  \\\n",
            "0  1. https://www.baeldung.com/spring-pathvariabl...      \n",
            "\n",
            "                               POST_model validation  \\\n",
            "0  After reviewing the 3rd-party web pages, the g...   \n",
            "\n",
            "                                  SerpAPI-found URLs  \n",
            "0  https://stackoverflow.com/questions/31403203/m...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ### STILL NOT THE ANSWER WEB PAGE IS LOCATED!!! ###\n",
        "# ## I thought I need (1) better query construction, (2) multi-query searching, and (3) a simple reranker.\n",
        "# # Below is a drop-in that fixes bugs, adds strong Google operators, runs several candidates, and\n",
        "# # ranks results by “Hibernate/@Find”-likeness. I also add clean exclusions + host priorities.\n",
        "\n",
        "# from __future__ import annotations\n",
        "# import os, re, time, json, math\n",
        "# from typing import List, Optional, Set, Dict, Iterable, Tuple\n",
        "# from urllib.parse import urlparse\n",
        "# import requests\n",
        "\n",
        "# # -------------------------------\n",
        "# # Config\n",
        "# # -------------------------------\n",
        "# SERPAPI_API_KEY = userdata.get(\"SERPAPI_API_KEY\")\n",
        "# DEFAULT_EXCLUDES: Set[str] = {\n",
        "#     \"facebook.com\",\"x.com\",\"twitter.com\",\"pinterest.com\",\"youtube.com\",\n",
        "#     \"linkedin.com\",\"tiktok.com\",\"instagram.com\",\"buffercdn.com\"\n",
        "# }\n",
        "\n",
        "# # Prefer official docs that likely contain @Find\n",
        "# HOST_PRIORITY: Dict[str, int] = {\n",
        "#     \"docs.jboss.org\": 100,             # Hibernate javadocs\n",
        "#     \"hibernate.org\": 95,               # Hibernate website\n",
        "#     \"jakarta.ee\": 80,                  # EE docs\n",
        "#     \"jetbrains.com\": 70,               # Inspectopedia/IDEA docs\n",
        "#     \"github.com\": 40,                  # Code often useful\n",
        "# }\n",
        "\n",
        "# # -------------------------------\n",
        "# # Helpers\n",
        "# # -------------------------------\n",
        "# def host_of(url: str) -> str:\n",
        "#     try:\n",
        "#         return urlparse(url).netloc.lower()\n",
        "#     except Exception:\n",
        "#         return \"\"\n",
        "\n",
        "# def is_excluded(url: str, excluded_hosts: Set[str]) -> bool:\n",
        "#     h = host_of(url)\n",
        "#     return any(h == ex or h.endswith(f\".{ex}\") for ex in excluded_hosts)\n",
        "\n",
        "# def uniq_preserve_order(seq: Iterable[str]) -> List[str]:\n",
        "#     seen = set()\n",
        "#     out = []\n",
        "#     for s in seq:\n",
        "#         if s not in seen:\n",
        "#             seen.add(s)\n",
        "#             out.append(s)\n",
        "#     return out\n",
        "\n",
        "# # -------------------------------\n",
        "# # SerpAPI search (multi-query)\n",
        "# # -------------------------------\n",
        "# def serpapi_search(query: str, exclude_domains: Optional[Set[str]] = None, num: int = 10) -> List[dict]:\n",
        "#     \"\"\"\n",
        "#     Returns a *list of result dicts* (we keep title/snippet for reranking).\n",
        "#     \"\"\"\n",
        "#     if not SERPAPI_API_KEY:\n",
        "#         print(\"⚠️ No SerpAPI key provided.\")\n",
        "#         return []\n",
        "\n",
        "#     excludes = set(DEFAULT_EXCLUDES)\n",
        "#     if exclude_domains:\n",
        "#         excludes |= set(exclude_domains)\n",
        "\n",
        "#     params = {\"engine\": \"google\", \"q\": query, \"api_key\": SERPAPI_API_KEY, \"num\": str(num)}\n",
        "#     try:\n",
        "#         r = requests.get(\"https://serpapi.com/search\", params=params, timeout=20)\n",
        "#         r.raise_for_status()\n",
        "#         data = r.json()\n",
        "#         out = []\n",
        "#         for item in data.get(\"organic_results\", []):\n",
        "#             url = item.get(\"link\")\n",
        "#             if not url:\n",
        "#                 continue\n",
        "#             if is_excluded(url, excludes):\n",
        "#                 continue\n",
        "#             out.append({\n",
        "#                 \"url\": url,\n",
        "#                 \"title\": item.get(\"title\", \"\"),\n",
        "#                 \"snippet\": item.get(\"snippet\", \"\"),\n",
        "#                 \"position\": item.get(\"position\"),\n",
        "#             })\n",
        "#         return out\n",
        "#     except Exception as e:\n",
        "#         print(f\"⚠️ SerpAPI request failed: {e}\")\n",
        "#         return []\n",
        "\n",
        "# # -------------------------------\n",
        "# # Query building\n",
        "# # -------------------------------\n",
        "# def normalize_space(s: str) -> str:\n",
        "#     return re.sub(r\"\\s+\", \" \", s or \"\").strip()\n",
        "\n",
        "# def key_terms_from_text(text: str, k: int = 8) -> List[str]:\n",
        "#     \"\"\"\n",
        "#     Cheap, dependency-free keyterm picker: keep tokens with @, camelCase, or java-ish/Dot terms; fallback to frequent words.\n",
        "#     Replace with RAKE/TextRank if you like.\n",
        "#     \"\"\"\n",
        "#     if not text:\n",
        "#         return []\n",
        "#     toks = re.findall(r\"[@\\w\\.]+\", text)\n",
        "#     # keep distinctive tokens\n",
        "#     candidates = [t for t in toks if len(t) > 2]\n",
        "#     # light heuristic boosts\n",
        "#     def score(t: str) -> float:\n",
        "#         s = 0.0\n",
        "#         if t.startswith(\"@\"): s += 3\n",
        "#         if \".\" in t: s += 1.5   # package/class names\n",
        "#         if re.search(r\"[A-Z][a-z]+[A-Z]\", t): s += 1.0  # camelCase\n",
        "#         if t.lower() in {\"find\",\"finder\",\"annotation\",\"hibernate\",\"entity\",\"typedquery\",\"selectionquery\"}:\n",
        "#             s += 1.2\n",
        "#         return s\n",
        "#     ranked = sorted(candidates, key=lambda t: (score(t), len(t)), reverse=True)\n",
        "#     out = uniq_preserve_order(ranked)[:k]\n",
        "#     return out\n",
        "\n",
        "# def build_candidate_queries(framework: str, topic: str, jetbrains_intro: str, gpt5_expl: str) -> List[str]:\n",
        "#     \"\"\"\n",
        "#     Generate several strong Google queries with operators. We’ll try them all and then rerank results.\n",
        "#     \"\"\"\n",
        "#     ctx = normalize_space(\" \".join([framework or \"\", topic or \"\", jetbrains_intro or \"\", gpt5_expl or \"\"]))\n",
        "#     terms = key_terms_from_text(ctx)\n",
        "#     joined = \" \".join(terms) if terms else ctx\n",
        "\n",
        "#     # Pay special attention to '@Find' literal\n",
        "#     base = '\"@Find\" hibernate annotation'\n",
        "\n",
        "#     candidates = [\n",
        "#         # precision: official javadocs\n",
        "#         f'site:docs.jboss.org {base}',\n",
        "#         f'site:hibernate.org {base}',\n",
        "#         # title/url hints\n",
        "#         f'intitle:@Find hibernate annotation',\n",
        "#         f'inurl:hibernate intitle:@Find annotation',\n",
        "#         # allintext to bind concepts\n",
        "#         f'allintext:@Find hibernate entity finder {joined}',\n",
        "#         # combine with JetBrains if trying to verify Inspectopedia rule\n",
        "#         f'site:jetbrains.com Inspectopedia \"@Find\" hibernate',\n",
        "#         # fallback broad\n",
        "#         f'{base} {joined}',\n",
        "#     ]\n",
        "\n",
        "#     # de-duplicate + keep short, valid strings\n",
        "#     return uniq_preserve_order([normalize_space(c) for c in candidates if c.strip()])\n",
        "\n",
        "# # -------------------------------\n",
        "# # Lightweight reranking\n",
        "# # -------------------------------\n",
        "# def feature_score(result: dict) -> float:\n",
        "#     \"\"\"\n",
        "#     Score by: host priority, presence of '@Find' in title/snippet/url,\n",
        "#     path hints like '/annotations/processing/Find'.\n",
        "#     \"\"\"\n",
        "#     url, title, snip = result.get(\"url\",\"\"), result.get(\"title\",\"\"), result.get(\"snippet\",\"\")\n",
        "#     host = host_of(url)\n",
        "#     score = HOST_PRIORITY.get(host, 0)\n",
        "\n",
        "#     text = \" \".join([url, title, snip]).lower()\n",
        "#     boosts = [\n",
        "#         (r\"@find\", 15),\n",
        "#         (r\"\\bhibernate\\b\", 8),\n",
        "#         (r\"\\bannotation(s)?\\b\", 5),\n",
        "#         (r\"/annotations/processing/find\", 12),\n",
        "#         (r\"/javadocs/\", 10),\n",
        "#         (r\"\\bentity\\b\", 4),\n",
        "#     ]\n",
        "#     for pat, w in boosts:\n",
        "#         if re.search(pat, text):\n",
        "#             score += w\n",
        "\n",
        "#     # slight boost for earlier rank\n",
        "#     pos = result.get(\"position\")\n",
        "#     if isinstance(pos, int):\n",
        "#         score += max(0, 10 - pos)\n",
        "\n",
        "#     return float(score)\n",
        "\n",
        "# def rerank(results: List[dict]) -> List[dict]:\n",
        "#     return sorted(results, key=feature_score, reverse=True)\n",
        "\n",
        "# # -------------------------------\n",
        "# # Orchestrator\n",
        "# # -------------------------------\n",
        "# def search_framework_find(framework: str, topic: str,\n",
        "#                           jetbrains_intro: str, gpt5_expl: str,\n",
        "#                           exclude_domains: Optional[Set[str]] = None,\n",
        "#                           per_query: int = 10) -> List[dict]:\n",
        "#     queries = build_candidate_queries(framework, topic, jetbrains_intro, gpt5_expl)\n",
        "\n",
        "#     all_results: List[dict] = []\n",
        "#     for q in queries:\n",
        "#         batch = serpapi_search(q, exclude_domains=exclude_domains, num=per_query)\n",
        "#         all_results.extend(batch)\n",
        "#         time.sleep(0.2)  # be polite; SerpAPI handles rate limiting but avoid bursts\n",
        "\n",
        "#     # Deduplicate by URL\n",
        "#     dedup: Dict[str, dict] = {}\n",
        "#     for r in all_results:\n",
        "#         dedup[r[\"url\"]] = r\n",
        "#     ranked = rerank(list(dedup.values()))\n",
        "#     return ranked[:20]  # top-N\n",
        "\n",
        "\n",
        "# framework = FRAMEWORK            # e.g., \"Hibernate ORM 6.x\"\n",
        "# topic = TOPIC                    # e.g., \"Finder methods with @Find\"\n",
        "# jetbrains_intro = load_new_rule_explanation(GPT5_RULE_DESCRIPTION_PATH)   # scraped from JetBrains web page\n",
        "\n",
        "# gpt5_expl = load_gpt5_rule_description(newRULE_EXPLANATIONS_PATH)              # your own summary, optional\n",
        "\n",
        "# top = search_framework_find(framework, topic, jetbrains_intro, gpt5_expl)\n",
        "# for r in top[:5]:\n",
        "#     print(r[\"url\"], \"—\", r[\"title\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6Pnxs26WarE",
        "outputId": "267ba76c-6a85-4f45-f7fc-18065040c290"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚠️ No saved GPT-5 rule description found.\n",
            "https://docs.jboss.org/hibernate/orm/7.0/javadocs/org/hibernate/annotations/processing/Find.html — Find (Hibernate Javadocs)\n",
            "https://docs.jboss.org/hibernate/orm/6.3/javadocs/org/hibernate/annotations/processing/Find.html — Find (Hibernate Javadocs)\n",
            "https://docs.jboss.org/hibernate/orm/7.2/javadocs/org/hibernate/annotations/processing/package-summary.html — Package org.hibernate.annotations.processing\n",
            "https://docs.jboss.org/hibernate/orm/7.2/javadocs//org/hibernate/class-use/Incubating.html — Uses of Annotation Interface org.hibernate.Incubating\n",
            "https://docs.jboss.org/hibernate/orm/7.2/javadocs/org/hibernate/annotations/package-summary.html — Package org.hibernate.annotations\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, the answer web page was \"https://docs.jboss.org/hibernate/orm/7.0/javadocs/org/hibernate/annotations/processing/Find.html\""
      ],
      "metadata": {
        "id": "20MQAaIyYx45"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### TO-DOs ######\n",
        "# What if the one generated rule is too big?\n",
        "# Save the generated rule in json file or text file first then consult with Codex-GPT-5\n",
        "# To optimize the propmt, look into DsPY: https://adasci.org/dspy-streamlining-llm-prompt-optimization/\n",
        "# Using DsPy, we’ll configure our Language Model (GPT-3.5-turbo) and Retrieval Model (ColBERTv2). These will form the backbone of our RAG system.\n",
        "# Codex-GPT-5 could help break down the one (big) generated rule if it exceeds N lines - - will this be meaninful in terms of validation and running the MeCheck engine to check more granular rules?\n",
        "# Then, iterate the validation process with each sub-rule derived from the original rule both with GPT-5 and SerpAPI\n",
        "# We will Hibernate's incorrect @find annotation rule will be implemented into the current MeCheck engine\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ct5J7m_YMlec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####################################################OLD or MERGED FUNCTIONS ##############\n",
        "#########################################################################################\n",
        "\n",
        "\n",
        "# To save the gpt5-generated rule description based on the scraped content from the JetBrains webpage\n",
        "# import os, re, json, requests\n",
        "# from bs4 import BeautifulSoup\n",
        "# GPT5_RULE_DESCRIPTION_PATH = \"/content/gpt5_rule_description_scraped_content.json\"\n",
        "\n",
        "\n",
        "# # --- Save column “generated_rule_explanation from GPT-5” to JSON (list of strings) ---\n",
        "\n",
        "# generated_explanations = [str(x).strip() for x in df[\"generated_rule_explanation from GPT-5\"].fillna(\"\") if str(x).strip()]\n",
        "# single_explanation = generated_explanations[0] if generated_explanations else \"\"\n",
        "# with open(newRULE_EXPLANATIONS_PATH, \"w\", encoding=\"utf-8\") as f:\n",
        "#     json.dump(generated_explanations, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "# try:\n",
        "#     os.makedirs(os.path.dirname(newRULE_EXPLANATIONS_PATH), exist_ok=True)\n",
        "#     with open(newRULE_EXPLANATIONS_PATH, \"w\", encoding=\"utf-8\") as f:\n",
        "#         json.dump(\n",
        "#             {\"new_generated_rule_explanation\": single_explanation},\n",
        "#             f,\n",
        "#             ensure_ascii=False,\n",
        "#             indent=2\n",
        "#         )\n",
        "#     print(f\"✅ Saved new_generated_rule_explanation to {newRULE_EXPLANATIONS_PATH}\")\n",
        "# except Exception as e:\n",
        "#     print(f\"❌ Failed to save JSON: {e}\")\n",
        "\n",
        "\n",
        "# def fetch_text(url: str, timeout: int = 20) -> str:\n",
        "#     \"\"\"\n",
        "#     Fetches text content from the SOURCE URL.\n",
        "#     Cleans out scripts, styles, and noscript tags.\n",
        "#     \"\"\"\n",
        "#     url = SOURCE  # Always use the global SOURCE variable\n",
        "#     resp = requests.get(url, timeout=timeout)\n",
        "#     resp.raise_for_status()\n",
        "#     soup = BeautifulSoup(resp.text, \"html.parser\")\n",
        "#     for tag in soup([\"script\", \"style\", \"noscript\"]):\n",
        "#         tag.decompose()\n",
        "#     text = soup.get_text(separator=\"\\n\")\n",
        "#     text = re.sub(r\"\\n\\s*\\n+\", \"\\n\\n\", text).strip()\n",
        "#     return text\n",
        "\n",
        "\n",
        "# def source_intro_saved_json(url: str, path: str = GPT5_RULE_DESCRIPTION_PATH) -> str:\n",
        "#     \"\"\"\n",
        "#     Scrapes and saves only the portion of the JetBrains Inspectopedia page\n",
        "#     before the 'Locating this inspection' section into a JSON file.\n",
        "\n",
        "#     The text is also returned so you can preview or use it immediately.\n",
        "#     \"\"\"\n",
        "#     try:\n",
        "#         full = fetch_text(url)\n",
        "#     except Exception as e:\n",
        "#         print(f\"❌ Failed to fetch text from {url}: {e}\")\n",
        "#         return \"\"\n",
        "\n",
        "#     # Find the section before \"Locating this inspection\"\n",
        "#     m = re.search(r\"^\\s*Locating\\s+this\\s+inspection\\b\", full, flags=re.IGNORECASE | re.MULTILINE)\n",
        "#     if m:\n",
        "#         content_before = full[:m.start()].strip()\n",
        "#     else:\n",
        "#         content_before = full.strip()\n",
        "\n",
        "#     # Save to JSON file\n",
        "#     try:\n",
        "#         os.makedirs(os.path.dirname(path), exist_ok=True)\n",
        "#         with open(path, \"w\", encoding=\"utf-8\") as f:\n",
        "#             json.dump(\n",
        "#                 {\"jetbrains_scraped_rule_description\": content_before},\n",
        "#                 f,\n",
        "#                 ensure_ascii=False,\n",
        "#                 indent=2\n",
        "#             )\n",
        "#         print(f\"✅ Saved JetBrains scraped rule description context to {path}\")\n",
        "#     except Exception as e:\n",
        "#         print(f\"❌ Failed to save JSON: {e}\")\n",
        "\n",
        "#     return content_before\n",
        "\n",
        "\n",
        "# def load_new_rule_explanation(path: str = GPT5_RULE_DESCRIPTION_PATH) -> str:\n",
        "#     \"\"\"\n",
        "#     Loads the previously saved GPT-5 rule description for contextual use in SerpAPI searches.\n",
        "#     Returns an empty string if none exists or file is corrupted.\n",
        "#     \"\"\"\n",
        "#     if not os.path.exists(path):\n",
        "#         print(\"⚠️ No saved GPT-5 rule description found.\")\n",
        "#         return \"\"\n",
        "#     try:\n",
        "#         with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "#             data = json.load(f)\n",
        "#         return data.get(\"new_generated_rule_explanation\", \"\")\n",
        "#     except Exception as e:\n",
        "#         print(f\"⚠️ Failed to load saved description: {e}\")\n",
        "#         return \"\"\n",
        "\n",
        "# def load_gpt5_rule_description(path: str = newRULE_EXPLANATIONS_PATH) -> str:\n",
        "#     \"\"\"\n",
        "#     Loads the new-GPT-5-generated rule explanation to provide context to SerpAPI later.\n",
        "#     Returns an empty string if none exists or file is corrupted.\n",
        "#     \"\"\"\n",
        "#     if not os.path.exists(path):\n",
        "#         print(\"⚠️ No new-GPT-5 rule explanation found.\")\n",
        "#         return \"\"\n",
        "#     try:\n",
        "#         with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "#             data = json.load(f)\n",
        "#         return data.get(\"generated_rule_explanation from GPT-5\", \"\")\n",
        "#     except Exception as e:\n",
        "#         print(f\"⚠️ Failed to load saved description: {e}\")\n",
        "#         return \"\"\n",
        "\n",
        "# # Step 1: Scrape and save\n",
        "# context_text = source_intro_saved_json(SOURCE)\n",
        "# print(\"\\n--- Preview of saved content ---\\n\")\n",
        "# print(context_text[:500], \"...\")  # show the first 500 chars\n",
        "\n",
        "# # Step 2: Load later (e.g., in a new session)\n",
        "# loaded_text = load_new_rule_explanation(GPT5_RULE_DESCRIPTION_PATH)\n",
        "# print(\"\\n--- Loaded back from JSON scraped from JetBrains  ---\\n\")\n",
        "# print(loaded_text[:500], \"...\")\n",
        "\n",
        "# # Step 3: Load later (e.g., in a new session)\n",
        "# loaded_text1 = load_gpt5_rule_description(newRULE_EXPLANATIONS_PATH)\n",
        "# print(\"\\n--- Loaded back from JSON from gpt5_rule_explanation ---\\n\")\n",
        "# print(loaded_text1[:500], \"...\")\n",
        "\n",
        "#source_intro_before_locating(SOURCE)\n",
        "\n",
        "\n",
        "# def fetch_text(url: str, timeout: int = 20) -> str:\n",
        "#     url = SOURCE\n",
        "#     resp = requests.get(url, timeout=timeout)\n",
        "#     resp.raise_for_status()\n",
        "#     soup = BeautifulSoup(resp.text, \"html.parser\")\n",
        "#     for tag in soup([\"script\", \"style\", \"noscript\"]):\n",
        "#         tag.decompose()\n",
        "#     text = soup.get_text(separator=\"\\n\")\n",
        "#     text = re.sub(r\"\\n\\s*\\n+\", \"\\n\\n\", text).strip()\n",
        "#     return text\n",
        "\n",
        "# def source_intro_before_locating(url: str) -> str:\n",
        "#     \"\"\"\n",
        "#     Returns ONLY the part of the page before the 'Locating this inspection' section.\n",
        "#     Matches the header case-insensitively and robustly.\n",
        "#     \"\"\"\n",
        "#     full = fetch_text(url)\n",
        "#     # Some pages include non-breaking / special spaces; keep the match flexible.\n",
        "#     m = re.search(r\"^\\s*Locating\\s+this\\s+inspection\\b\", full, flags=re.IGNORECASE | re.MULTILINE)\n",
        "#     if m:\n",
        "#         return full[:m.start()].strip()\n",
        "#         #print(full.strip())\n",
        "\n",
        "#         with open(path, \"w\", encoding=\"utf-8\") as f:\n",
        "#              json.dump(full.strip(), f, ensure_ascii=False, indent=2)\n",
        "#              print(f\"✅ Saved GPT-5 rule description context to {path}\")\n",
        "#     return(full.strip())\n",
        "\n",
        "\n",
        "\n",
        "# def load_gpt5_rule_description(path: str = GPT5_RULE_DESCRIPTION_PATH) -> str:\n",
        "#     \"\"\"\n",
        "#     Loads the previously saved GPT-5 rule description for contextual use in SerpAPI searches.\n",
        "#     Returns an empty string if none exists.\n",
        "#     \"\"\"\n",
        "#     if not os.path.exists(path):\n",
        "#         return \"\"\n",
        "#     try:\n",
        "#         with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "#             data = json.load(f)\n",
        "#         return data.get(\"gpt5_generated_rule_description\", \"\")\n",
        "#     except Exception:\n",
        "#         return \"\"\n"
      ],
      "metadata": {
        "id": "_N7Jy1pWO88F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8O00_TN7xTt"
      },
      "source": [
        "# ###########################################\n",
        "# #### OLD CODES ######### DO NOT RUN!!!\n",
        "# ########################################\n",
        "# # --- Rule Validation Utilities (Using SerpAPI) ---\n",
        "# import requests, time, html, re\n",
        "# from typing import List, Dict, Set, Optional\n",
        "# from bs4 import BeautifulSoup\n",
        "\n",
        "# SERPAPI_API_KEY = userdata.get(\"SERPAPI_API_KEY\")\n",
        "\n",
        "# DEFAULT_EXCLUDES = {\n",
        "#     \"jetbrains.com\",\n",
        "#     \"www.jetbrains.com\",\n",
        "#     \"jetbrains.com.cn\",\n",
        "#     \"www.jetbrains.com.cn\",\n",
        "# }\n",
        "\n",
        "# def is_excluded(url: str, exclude_domains: Set[str]) -> bool:\n",
        "#     if not exclude_domains:\n",
        "#         return False\n",
        "#     u = url.lower()\n",
        "#     return any(dom.lower() in u for dom in exclude_domains)\n",
        "\n",
        "# def serpapi_search(query: str, exclude_domains: Set[str] = None) -> List[str]:\n",
        "#     \"\"\"\n",
        "#     Search with SerpAPI and return non-excluded URLs.\n",
        "#     JetBrains domains are ALWAYS excluded to ensure third-party sources.\n",
        "#     \"\"\"\n",
        "#     if not SERPAPI_API_KEY:\n",
        "#         return []\n",
        "#     try:\n",
        "#         # merge user excludes with default JetBrains excludes\n",
        "#         merged_excludes = set(DEFAULT_EXCLUDES)\n",
        "#         if exclude_domains:\n",
        "#             merged_excludes |= set(exclude_domains)\n",
        "\n",
        "#         params = {\"engine\": \"google\",\"q\": query,\"api_key\": SERPAPI_API_KEY,\"num\": \"10\"}\n",
        "#         resp = requests.get(\"https://serpapi.com/search\", params=params, timeout=20)\n",
        "#         data = resp.json()\n",
        "#         results = []\n",
        "#         for item in data.get(\"organic_results\", []):\n",
        "#             url = item.get(\"link\")\n",
        "#             if url and not is_excluded(url, merged_excludes):\n",
        "#                 results.append(url)\n",
        "#         return results\n",
        "#     except Exception:\n",
        "#         return []\n",
        "\n",
        "# # def build_query_from_rule(rule_text: str) -> str:\n",
        "# #     tokens = [t for t in re.split(r'\\W+', rule_text) if t]\n",
        "# #     key = \" \".join(tokens[:8])\n",
        "# #     return f\"{key} error inspection rule\"\n",
        "\n",
        "# # def build_query_from_rule(rule_text: str) -> str:\n",
        "# #     m = re.search(r'Rule\\s+([\\w\\-]+)', rule_text)\n",
        "# #     print(\"Rule name:\", m.group(1) if m else \"unavailable\")\n",
        "# #     rule_name = m.group(1) if m else f\"{TOPIC}\"\n",
        "# #     return f\"{rule_name} {TOPIC}\"\n",
        "# def build_query_from_rule(rule: dict | str) -> str:\n",
        "#     \"\"\"\n",
        "#     Build a web search query using contextual information derived from:\n",
        "#       - The JetBrains Inspectopedia SOURCE page (up to 'Locating this inspection')\n",
        "#       - Its summarized content via GPT-5\n",
        "#       - The given rule (dict or string)\n",
        "\n",
        "#     The resulting query is semantically focused on the rule’s core description,\n",
        "#     not its literal name, and ends with FRAMEWORK and TOPIC.\n",
        "#     \"\"\"\n",
        "#     # 1️⃣ Extract rule text (fallback to string)\n",
        "#     if isinstance(rule, dict):\n",
        "#         base_text = rule.get(\"rule\") or rule.get(\"name\") or rule.get(\"description\") or \"\"\n",
        "#         print(\"base_text: \", base_text)\n",
        "#     else:\n",
        "#         base_text = str(rule)\n",
        "\n",
        "#     # 2️⃣ Fetch JetBrains Inspectopedia page content\n",
        "#     try:\n",
        "#         full_text = _fetch_text(SOURCE)\n",
        "#         # Keep only the portion before \"Locating this inspection\"\n",
        "#         cutoff = re.search(r\"Locating\\s+this\\s+inspection\", full_text, flags=re.IGNORECASE)\n",
        "#         if cutoff:\n",
        "#             source_text = full_text[:cutoff.start()]\n",
        "#         else:\n",
        "#             source_text = full_text\n",
        "#         source_text = source_text.strip()[:20000]  # safety cap\n",
        "#     except Exception as e:\n",
        "#         source_text = f\"(JetBrains fetch error: {e})\"\n",
        "\n",
        "#     # 3️⃣ Summarize JetBrains content (no temperature param)\n",
        "#     try:\n",
        "#         prompt = (\n",
        "#             \"Summarize the following JetBrains Inspectopedia documentation \"\n",
        "#             \"in 1-2 sentences focusing on the core inspection purpose or behavior:\\n\\n\"\n",
        "#             f\"{source_text}\"\n",
        "#         )\n",
        "#         comp = client.chat.completions.create(\n",
        "#             model=\"gpt-5\",\n",
        "#             messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "#         )\n",
        "#         jb_summary = comp.choices[0].message.content.strip()\n",
        "#     except Exception as e:\n",
        "#         jb_summary = f\"Summary unavailable (GPT error: {e})\"\n",
        "\n",
        "#     # 4️⃣ Merge rule text + JetBrains summary → keywords\n",
        "#     tokens = [t for t in re.split(r'\\W+', f\"{jb_summary} {base_text}\") if t]\n",
        "#     key = \" \".join(tokens[:10]) if tokens else FRAMEWORK\n",
        "\n",
        "#     # 5️⃣ Return final query anchored to FRAMEWORK and TOPIC\n",
        "#     return f\"{key} {FRAMEWORK} {TOPIC}\"\n",
        "\n",
        "\n",
        "\n",
        "# def validate_rule_via_serpapi(rule_text: str,\n",
        "#                               exclude_domains: Optional[Set[str]] = None,\n",
        "#                               max_urls: int = 2) -> Dict[str, object]:\n",
        "#     q = build_query_from_rule(rule_text)\n",
        "#     urls = serpapi_search(q, exclude_domains or set())\n",
        "#     return {\"query\": q, \"urls\": urls[:max_urls]}\n",
        "\n",
        "# # JETBRAINS_DOC_URL = \"https://www.jetbrains.com.cn/en-us/help/inspectopedia/MnUnresolvedPathVariable.html\"\n",
        "\n",
        "# def _fetch_text(url: str, timeout: int = 20) -> str:\n",
        "#     resp = requests.get(url, timeout=timeout)\n",
        "#     resp.raise_for_status()\n",
        "#     soup = BeautifulSoup(resp.text, \"html.parser\")\n",
        "#     for tag in soup([\"script\",\"style\",\"noscript\"]):\n",
        "#         tag.decompose()\n",
        "#     text = soup.get_text(separator=\"\\n\")\n",
        "#     text = re.sub(r\"\\n\\s*\\n+\", \"\\n\\n\", text).strip()\n",
        "#     return text\n",
        "\n",
        "# def summarize_third_party(url: str, client, model: str = \"gpt-5\", temperature: float = 1) -> str:\n",
        "#     \"\"\"\n",
        "#     Fetch a third-party URL and summarize its content briefly.\n",
        "#     \"\"\"\n",
        "#     try:\n",
        "#         content = _fetch_text(url)[:20000]\n",
        "#     except Exception as e:\n",
        "#         return f\"Summary unavailable (fetch error: {e})\"\n",
        "#     prompt = (\n",
        "#         \"Summarize the following web page in 2-3 concise sentences, \"\n",
        "#         \"focusing on information relevant to static analysis rules or inspections.\\n\\n\"\n",
        "#         f\"Content:\\n{content}\"\n",
        "#     )\n",
        "#     try:\n",
        "#         comp = client.chat.completions.create(\n",
        "#             model=model,\n",
        "#             messages=[{\"role\":\"user\",\"content\":prompt}],\n",
        "#             temperature=temperature,\n",
        "#         )\n",
        "#         return comp.choices[0].message.content.strip()\n",
        "#     except Exception as e:\n",
        "#         return f\"Summary unavailable (GPT error: {e})\"\n",
        "\n",
        "# def secondary_validation_via_jetbrains_gpt(rule_text: str,\n",
        "#                                            client,\n",
        "#                                            model: str = \"gpt-5\"\n",
        "#                                            ) -> str:\n",
        "#     \"\"\"\n",
        "#     Uses the JetBrains Inspectopedia page to validate the rule in one sentence.\n",
        "#     \"\"\"\n",
        "#     try:\n",
        "#         source_text = _fetch_text(SOURCE)[:30000]\n",
        "#     except Exception as e:\n",
        "#         return f\"Secondary validation skipped (JetBrains fetch error: {e})\"\n",
        "\n",
        "#     system_msg = (\n",
        "#         \"You are a precise static-analysis assistant. Validate a proposed rule \"\n",
        "#         \"STRICTLY using the provided JetBrains Inspectopedia excerpt. \"\n",
        "#         \"Respond with a single short sentence stating whether the rule aligns with the doc and why.\"\n",
        "#     )\n",
        "#     user_msg = (\n",
        "#         f\"Rule to validate:\\n{rule_text}\\n\\n\"\n",
        "#         f\"JetBrains Inspectopedia source (excerpt):\\n{source_text}\"\n",
        "#     )\n",
        "#     try:\n",
        "#         comp = client.chat.completions.create(\n",
        "#             model=model,\n",
        "#             messages=[\n",
        "#                 {\"role\": \"system\", \"content\": system_msg},\n",
        "#                 {\"role\": \"user\", \"content\": user_msg},\n",
        "#             ],\n",
        "#             #temperature=temperature,\n",
        "#         )\n",
        "#         return comp.choices[0].message.content.strip()\n",
        "#     except Exception as e:\n",
        "#         return f\"Secondary validation failed to run GPT: {e}\"\n",
        "\n",
        "# def combined_secondary_validation(rule_text: str,\n",
        "#                                   third_party_text: str,\n",
        "#                                   client,\n",
        "#                                   model: str = \"gpt-5\"\n",
        "#                                  ) -> str:\n",
        "#     \"\"\"\n",
        "#     Validate the rule using BOTH JetBrains Inspectopedia (fetched live) and the third-party page text.\n",
        "#     Output: one short sentence that references alignment or mismatch.\n",
        "#     \"\"\"\n",
        "#     try:\n",
        "#         jb_text = _fetch_text(SOURCE)[:20000]\n",
        "#     except Exception as e:\n",
        "#         jb_text = f\"(JetBrains fetch error: {e})\"\n",
        "#     system_msg = (\n",
        "#         \"You are a precise static-analysis assistant. Validate the proposed rule \"\n",
        "#         \"STRICTLY using the provided JetBrains Inspectopedia excerpt AND the provided third-party page. \"\n",
        "#         \"Respond with one short sentence stating whether the rule is consistent with these sources and why.\"\n",
        "#     )\n",
        "#     user_msg = (\n",
        "#         f\"Rule:\\n{rule_text}\\n\\n\"\n",
        "#         f\"JetBrains Inspectopedia excerpt:\\n{jb_text}\\n\\n\"\n",
        "#         f\"Third-party page excerpt:\\n{third_party_text[:8000]}\"\n",
        "#     )\n",
        "#     try:\n",
        "#         comp = client.chat.completions.create(\n",
        "#             model=model,\n",
        "#             messages=[\n",
        "#                 {\"role\": \"system\", \"content\": system_msg},\n",
        "#                 {\"role\": \"user\", \"content\": user_msg},\n",
        "#             ],\n",
        "#            # temperature=temperature,\n",
        "#         )\n",
        "#         return comp.choices[0].message.content.strip()\n",
        "#     except Exception as e:\n",
        "#         return f\"Combined validation failed (GPT error: {e})\"\n",
        "\n",
        "# print(\"✅ Helpers updated: SerpAPI now excludes JetBrains; added summarization and combined validation\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNsi59WG7xTu"
      },
      "source": [
        "# ###########################################\n",
        "# #### OLD CODES ######### DO NOT RUN\n",
        "# ########################################\n",
        "\n",
        "# # --- Demo: validate first generated rule (if available) ---\n",
        "# try:\n",
        "#     sample_rule = rules[0] if isinstance(rules, list) else rules\n",
        "#     if isinstance(sample_rule, dict) and \"rule\" in sample_rule:\n",
        "#         text = sample_rule[\"rule\"]\n",
        "#     else:\n",
        "#         text = json.dumps(sample_rule) if sample_rule else \"unavailable\"\n",
        "#     print(\"Rule sample:\", str(text)[:200], \"...\")\n",
        "#     print(\"\\n[Primary] SerpAPI URLs:\")\n",
        "#     out = validate_rule_via_serpapi(str(text), exclude_domains={\"jetbrains.com\",\"jetbrains.com.cn\",\"microsoft.com\"})\n",
        "#     for u in out[\"urls\"]:\n",
        "#         print(\" -\", u)\n",
        "#     print(\"\\n[Secondary] GPT-5 x JetBrains Inspectopedia:\")\n",
        "#     print(secondary_validation_via_jetbrains_gpt(str(text), client))\n",
        "# except Exception as e:\n",
        "#     print(\"Demo skipped:\", e)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9j2bTsc7xTu"
      },
      "source": [
        "# ###########################################\n",
        "# #### OLD CODES ######### DO NOT RUN\n",
        "# ########################################\n",
        "# # --- Post-processing: save third-party URL, its summary, and GPT validation into CSV ---\n",
        "# import pandas as pd\n",
        "# import json\n",
        "\n",
        "# def _get_rule_text(x):\n",
        "#     if isinstance(x, dict):\n",
        "#         # try typical keys\n",
        "#         for k in (\"rule\", \"name\", \"title\", \"description\"):\n",
        "#             if k in x:\n",
        "#                 return str(x[k])\n",
        "#         return json.dumps(x)\n",
        "#     return str(x)\n",
        "\n",
        "# # Decide input set\n",
        "# try:\n",
        "#     df = pd.read_csv(\"rsl_generated_rules.csv\")\n",
        "#     # If rules variable exists, prefer it (might be fresher) and rebuild df\n",
        "#     if \"rules\" in globals():\n",
        "#         candidate = rules\n",
        "#         if isinstance(candidate, list):\n",
        "#             # try to preserve columns if dicts\n",
        "#             df = pd.DataFrame(candidate)\n",
        "#         else:\n",
        "#             df = pd.DataFrame([candidate])\n",
        "# except FileNotFoundError:\n",
        "#     # fall back to rules in-memory\n",
        "#     if \"rules\" in globals():\n",
        "#         candidate = rules\n",
        "#         if isinstance(candidate, list):\n",
        "#             df = pd.DataFrame(candidate)\n",
        "#         else:\n",
        "#             df = pd.DataFrame([candidate])\n",
        "#     else:\n",
        "#         raise RuntimeError(\"No rules found. Generate rules before running this cell.\")\n",
        "\n",
        "# if df.empty:\n",
        "#     raise RuntimeError(\"Rules dataframe is empty.\")\n",
        "\n",
        "# third_urls = []\n",
        "# third_summaries = []\n",
        "# gpt_validations = []\n",
        "\n",
        "# for idx, row in df.iterrows():\n",
        "#     rule_text = _get_rule_text(row.to_dict())\n",
        "#     out = validate_rule_via_serpapi(rule_text, exclude_domains=set())  # JetBrains excluded by default\n",
        "#     url = out[\"urls\"][0] if out[\"urls\"] else \"\"\n",
        "#     third_urls.append(url)\n",
        "\n",
        "#     if url:\n",
        "#         try:\n",
        "#             page_text = _fetch_text(url)[:20000]\n",
        "#         except Exception as e:\n",
        "#             page_text = f\"(fetch error: {e})\"\n",
        "#         # summarize\n",
        "#         summ = summarize_third_party(url, client)\n",
        "#         third_summaries.append(summ)\n",
        "#         # combined validation (JetBrains + third-party content)\n",
        "#         valid = combined_secondary_validation(rule_text, page_text, client)\n",
        "#         gpt_validations.append(valid)\n",
        "#     else:\n",
        "#         third_summaries.append(\"No third-party page found\")\n",
        "#         gpt_validations.append(\"No third-party page; combined validation skipped\")\n",
        "\n",
        "# # Add/update columns\n",
        "# df[\"third_party_url\"] = third_urls\n",
        "# df[\"third_party_summary\"] = third_summaries\n",
        "# df[\"gpt_combined_validation\"] = gpt_validations\n",
        "\n",
        "# # Save back\n",
        "# df.to_csv(\"rsl_generated_rules.csv\", index=False)\n",
        "# print(\"✅ Updated rsl_generated_rules.csv with third_party_url, third_party_summary, gpt_combined_validation\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5GXoOXgJHkwb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}